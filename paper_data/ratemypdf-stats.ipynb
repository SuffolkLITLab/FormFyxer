{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brycew/Developer/LITLab/litlab_venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import var\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from formfyxer import lit_explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_expert = pd.read_excel(\"RateMyPDF Individual Form Expert Benchmarks(1-176).xlsx\")\n",
    "form_column = \"What form are you scoring? Please include the full URL, like: https://courtformsonline.org/forms/6e420f1b3575cfd8ef94b71977da9e38252e3395a78439709c760de4.pdf\\n\"\n",
    "rating_column = \"From 1-5, with 1 being the easiest and 5 being the hardest, how complex do you think this form is?\\n \"\n",
    "name_column = \"Full name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3185248/3867465554.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['form_name'] = df[form_column].apply(lambda y: y.split(\"/\")[-1].strip())\n",
      "/tmp/ipykernel_3185248/3867465554.py:6: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  sorted_experts = df.groupby('form_name').mean().sort_values(by='z_score', ascending=True).reset_index()\n"
     ]
    }
   ],
   "source": [
    "df = all_expert[[form_column, rating_column, name_column]]\n",
    "df[\"form_name\"] = df[form_column].apply(lambda y: y.split(\"/\")[-1].strip())\n",
    "mean_and_stddev = (\n",
    "    df.groupby(name_column)[rating_column]\n",
    "    .agg([\"mean\", \"std\"])\n",
    "    .rename(columns={\"mean\": \"reviewer_mean\", \"std\": \"reviewer_stddev\"})\n",
    "    .reset_index()\n",
    ")\n",
    "df = pd.merge(df, mean_and_stddev, on=name_column)\n",
    "df[\"z_score\"] = (df[rating_column] - df[\"reviewer_mean\"]) / df[\"reviewer_stddev\"]\n",
    "sorted_experts = (\n",
    "    df.groupby(\"form_name\")\n",
    "    .mean()\n",
    "    .sort_values(by=\"z_score\", ascending=True)\n",
    "    .reset_index()\n",
    ")\n",
    "# df.groupby(name_column).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n",
      "Detecting Sentences...\n",
      "Starting to find passives...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import shutil\n",
    "\n",
    "\n",
    "def calc_score(fname):\n",
    "    # full_url = \"https://courtformsonline.org/forms/\" + fname\n",
    "    # local_filename = \"/tmp/\" + fname\n",
    "    # with requests.get(full_url, stream=True) as r:\n",
    "    #  with open(local_filename, 'wb') as f:\n",
    "    #    shutil.copyfileobj(r.raw, f)\n",
    "    # The already downloaded and re-formated field PDFs, the ones that the stats are from in the paper.\n",
    "    local_filename = \"../../../tmp3/\" + fname\n",
    "    stats = lit_explorer.parse_form(local_filename)\n",
    "    return lit_explorer.form_complexity(stats)\n",
    "\n",
    "\n",
    "sorted_experts[\"our_complexity_score\"] = sorted_experts[\"form_name\"].apply(calc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_experts[\"z_complexity_score\"] = (\n",
    "    sorted_experts[\"our_complexity_score\"]\n",
    "    - np.mean(sorted_experts[\"our_complexity_score\"])\n",
    ") / np.std(sorted_experts[\"our_complexity_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions are used to count the number of adjacent swaps needed\n",
    "# to change one ordering into another. It was written by Shivam Gupta\n",
    "# See https://www.geeksforgeeks.org/number-swaps-sort-adjacent-swapping-allowed/\n",
    "# -----------------------------------------------------\n",
    "# python 3 program to count number of swaps required\n",
    "# to sort an array when only swapping of adjacent\n",
    "# elements is allowed.\n",
    "# include <bits/stdc++.h>\n",
    "\n",
    "\n",
    "# This function merges two sorted arrays and returns inversion count in the arrays.*/\n",
    "def merge(arr, temp, left, mid, right):\n",
    "    inv_count = 0\n",
    "\n",
    "    i = left  # i is index for left subarray*/\n",
    "    j = mid  # i is index for right subarray*/\n",
    "    k = left  # i is index for resultant merged subarray*/\n",
    "    while (i <= mid - 1) and (j <= right):\n",
    "        if arr[i] <= arr[j]:\n",
    "            temp[k] = arr[i]\n",
    "            k += 1\n",
    "            i += 1\n",
    "        else:\n",
    "            temp[k] = arr[j]\n",
    "            k += 1\n",
    "            j += 1\n",
    "\n",
    "            # this is tricky -- see above explanation/\n",
    "            # diagram for merge()*/\n",
    "            inv_count = inv_count + (mid - i)\n",
    "\n",
    "    # Copy the remaining elements of left subarray\n",
    "    # (if there are any) to temp*/\n",
    "    while i <= mid - 1:\n",
    "        temp[k] = arr[i]\n",
    "        k += 1\n",
    "        i += 1\n",
    "\n",
    "    # Copy the remaining elements of right subarray\n",
    "    # (if there are any) to temp*/\n",
    "    while j <= right:\n",
    "        temp[k] = arr[j]\n",
    "        k += 1\n",
    "        j += 1\n",
    "\n",
    "    # Copy back the merged elements to original array*/\n",
    "    for i in range(left, right + 1, 1):\n",
    "        arr[i] = temp[i]\n",
    "\n",
    "    return inv_count\n",
    "\n",
    "\n",
    "# An auxiliary recursive function that sorts the input\n",
    "# array and returns the number of inversions in the\n",
    "# array. */\n",
    "def _mergeSort(arr, temp, left, right):\n",
    "    inv_count = 0\n",
    "    if right > left:\n",
    "        # Divide the array into two parts and call\n",
    "        # _mergeSortAndCountInv()\n",
    "        # for each of the parts */\n",
    "        mid = int((right + left) / 2)\n",
    "\n",
    "        # Inversion count will be sum of inversions in\n",
    "        # left-part, right-part and number of inversions\n",
    "        # in merging */\n",
    "        inv_count = _mergeSort(arr, temp, left, mid)\n",
    "        inv_count += _mergeSort(arr, temp, mid + 1, right)\n",
    "\n",
    "        # Merge the two parts*/\n",
    "        inv_count += merge(arr, temp, left, mid + 1, right)\n",
    "\n",
    "    return inv_count\n",
    "\n",
    "\n",
    "# This function sorts the input array and returns the\n",
    "# number of inversions in the array */\n",
    "def countSwaps(arr):\n",
    "    n = len(arr)\n",
    "    temp = [0 for i in range(n)]\n",
    "    return _mergeSort(arr, temp, 0, n - 1)  # Time to get random sorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sort count: 386.7084\n",
      "Machine sort count: 299.0\n"
     ]
    }
   ],
   "source": [
    "# Time to get sorts\n",
    "def get_avg_sort_count(df, final_order_col, sort_by, runs=1):\n",
    "    swap_counts = []\n",
    "    for i in range(runs):\n",
    "        if sort_by == \"random\":\n",
    "            array = df[final_order_col].sample(frac=1).values.copy()\n",
    "        else:\n",
    "            df = df.sample(frac=1).sort_values(by=sort_by, ascending=True)\n",
    "            array = df[final_order_col].values.copy()\n",
    "        swap_counts.append(countSwaps(array))\n",
    "    return np.array(swap_counts).mean()\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Random sort count: {get_avg_sort_count(sorted_experts, 'z_score', 'random', runs=5000)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Machine sort count: {get_avg_sort_count(sorted_experts, 'z_score', 'z_complexity_score', runs=5000)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy_cohen_kappa: 0.6206896551724137\n"
     ]
    }
   ],
   "source": [
    "# Time to get cohen's kappa\n",
    "# put both ours and theirs back into bins.\n",
    "bins = [-3, -2, -1, 0, 1, 2, 3]\n",
    "expert_bins = np.digitize(sorted_experts[\"z_score\"], bins=bins)\n",
    "algo_bins = np.digitize(sorted_experts[\"z_complexity_score\"], bins=bins)\n",
    "print(\n",
    "    f'scipy_cohen_kappa: {cohen_kappa_score(expert_bins, algo_bins, weights=\"quadratic\")}'\n",
    ")\n",
    "# print(stats.ttest_rel())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "litlab_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
