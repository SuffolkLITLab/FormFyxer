{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc93a668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd625018f6247fab661ce6d838cb40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ctypes.wintypes import SHORT\n",
    "from dataclasses import Field\n",
    "import enum\n",
    "import os\n",
    "import re\n",
    "from sklearn.metrics import classification_report\n",
    "import spacy\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "# import PyPDF2\n",
    "import pikepdf\n",
    "import textstat\n",
    "import requests\n",
    "import json\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import unique\n",
    "from numpy import where\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "from joblib import load\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from PassivePySrc import PassivePy\n",
    "import eyecite\n",
    "from enum import Enum\n",
    "import sigfig\n",
    "\n",
    "try:\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    stopwords.words\n",
    "except:\n",
    "    print(\"Downloading stopwords\")\n",
    "    nltk.download(\"stopwords\")\n",
    "    from nltk.corpus import stopwords\n",
    "try:\n",
    "    nltk.data.find(\"tokenizers/punkt\")\n",
    "except:\n",
    "    nltk.download(\"punkt\")\n",
    "\n",
    "import math\n",
    "from contextlib import contextmanager\n",
    "import threading\n",
    "import _thread\n",
    "from typing import (\n",
    "    Optional,\n",
    "    Union,\n",
    "    BinaryIO,\n",
    "    Iterable,\n",
    "    List,\n",
    "    Dict,\n",
    "    Tuple,\n",
    "    Callable,\n",
    "    TypedDict,\n",
    ")\n",
    "from pathlib import Path\n",
    "\n",
    "import openai\n",
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e158174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "if 1==2:\n",
    "    try:\n",
    "        # this takes a while to load\n",
    "        import en_core_web_lg\n",
    "\n",
    "        nlp = en_core_web_lg.load()\n",
    "    except:\n",
    "        print(\"Downloading word2vec model en_core_web_lg\")\n",
    "        import subprocess\n",
    "\n",
    "        bashCommand = \"python -m spacy download en_core_web_lg\"\n",
    "        process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "        output, error = process.communicate()\n",
    "        print(f\"output of word2vec model download: {str(output)}\")\n",
    "        import en_core_web_lg\n",
    "\n",
    "        nlp = en_core_web_lg.load()\n",
    "\n",
    "    passivepy = PassivePy.PassivePyAnalyzer(nlp=nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92019651",
   "metadata": {},
   "source": [
    "Load local variables, models, and API key(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acabc498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['users1_name', 'users1_birthdate', 'users1_address_line_one', 'users1_address_line_two', 'users1_address_city', 'users1_address_state', 'users1_address_zip', 'users1_phone_number', 'users1_email', 'plantiffs1_name', 'defendants1_name', 'petitioners1_name', 'respondents1_name', 'docket_number', 'trial_court_county', 'users1_signature', 'signature_date'] ['state'] ['state']\n"
     ]
    }
   ],
   "source": [
    "# load local stuff\n",
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "included_fields = load(\"../formfyxer/data/included_fields.joblib\")\n",
    "jurisdictions = load(\"../formfyxer/data/jurisdictions.joblib\")\n",
    "groups = load(\"../formfyxer/data/groups.joblib\")\n",
    "clf_field_names = load(\"../formfyxer/data/clf_field_names.joblib\")\n",
    "with open(\"../../keys/tools_token.txt\", \"r\") as file:\n",
    "    tools_token = file.read().rstrip()\n",
    "with open(\"../../keys/spot_token.txt\", \"r\") as file:\n",
    "    spot_token = file.read().rstrip()\n",
    "with open(\"../../keys/openai_org.txt\", \"r\") as file:\n",
    "    openai.organization = file.read().rstrip()\n",
    "with open(\"../../keys/openai_key.txt\", \"r\") as file:\n",
    "    openai.api_key = file.read().rstrip()\n",
    "\n",
    "print(included_fields, jurisdictions, groups)\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2498467",
   "metadata": {},
   "source": [
    "This creates a timeout exception that can be triggered when something hangs too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04a97751",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeoutException(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def time_limit(seconds: float):\n",
    "    timer = threading.Timer(seconds, lambda: _thread.interrupt_main())\n",
    "    timer.start()\n",
    "    try:\n",
    "        yield\n",
    "    except KeyboardInterrupt:\n",
    "        raise TimeoutException(\"Timed out.\")\n",
    "    finally:\n",
    "        # if the action ends in specified time, timer is canceled\n",
    "        timer.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afa1a39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timed out!\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "import time\n",
    "\n",
    "try:\n",
    "    with time_limit(1):\n",
    "        time.sleep(3)\n",
    "except TimeoutException as e:\n",
    "    print(\"Timed out!\")\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc54fedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_get_id(values_to_unpack: Union[dict, list], tmpl: Optional[set] = None):\n",
    "    \"\"\"\n",
    "    Pull ID values out of the LIST/NSMI results from Spot.\n",
    "    \"\"\"\n",
    "    # h/t to Quinten and Bryce for this code ;)\n",
    "    if not tmpl:\n",
    "        tmpl = set()\n",
    "    if isinstance(values_to_unpack, dict):\n",
    "        tmpl.add(values_to_unpack.get(\"id\"))\n",
    "        if values_to_unpack.get(\"children\"):\n",
    "            tmpl.update(recursive_get_id(values_to_unpack.get(\"children\", []), tmpl))\n",
    "        return tmpl\n",
    "    elif isinstance(values_to_unpack, list):\n",
    "        for item in values_to_unpack:\n",
    "            tmpl.update(recursive_get_id(item, tmpl))\n",
    "        return tmpl\n",
    "    else:\n",
    "        return set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89f83578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HO-00-00-00-00', 'HO-06-00-00-00'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "spot_output = {\n",
    "    \"build\": 9,\n",
    "    \"query-id\": \"0dd2c6502bd64c76ae70b18d1c33029f\",\n",
    "    \"text\": \"My landlord is kicking me out of my home!\",\n",
    "    \"save-text\": 0,\n",
    "    \"cutoff-lower\": 0.25,\n",
    "    \"cutoff-pred\": 0.5,\n",
    "    \"cutoff-upper\": 0.6,\n",
    "    \"labels\": [\n",
    "        {\n",
    "            \"id\": \"HO-00-00-00-00\",\n",
    "            \"name\": \"Housing\",\n",
    "            \"lower\": 0.6576830054321086,\n",
    "            \"pred\": 0.6982554666277648,\n",
    "            \"upper\": 0.7171144999635295,\n",
    "            \"children\": [\n",
    "                {\n",
    "                    \"id\": \"HO-06-00-00-00\",\n",
    "                    \"name\": \"Renting or leasing a home\",\n",
    "                    \"lower\": 0.6705320866392293,\n",
    "                    \"pred\": 0.8859675570562203,\n",
    "                    \"upper\": 0.9113575931804385,\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "recursive_get_id(spot_output[\"labels\"])\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "876d0bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spot(\n",
    "    text: str,\n",
    "    lower: float = 0.25,\n",
    "    pred: float = 0.5,\n",
    "    upper: float = 0.6,\n",
    "    verbose: float = 0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Call the Spot API (https://spot.suffolklitlab.org) to classify the text of a PDF using\n",
    "    the NSMIv2/LIST taxonomy (https://taxonomy.legal/), but returns only the IDs of issues found in the text.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer \" + spot_token,\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    body = {\n",
    "        \"text\": text,\n",
    "        \"save-text\": 0,\n",
    "        \"cutoff-lower\": lower,\n",
    "        \"cutoff-pred\": pred,\n",
    "        \"cutoff-upper\": upper,\n",
    "    }\n",
    "    r = requests.post(\n",
    "        \"https://spot.suffolklitlab.org/v0/entities-nested/\",\n",
    "        headers=headers,\n",
    "        data=json.dumps(body),\n",
    "    )\n",
    "    output_ = r.json()\n",
    "    try:\n",
    "        output_[\"build\"]\n",
    "        if verbose != 1:\n",
    "            try:\n",
    "                return list(recursive_get_id(output_[\"labels\"]))\n",
    "            except:\n",
    "                return []\n",
    "        else:\n",
    "            return output_\n",
    "    except:\n",
    "        return output_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "331d47a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'build': 10,\n",
       " 'query-id': '493cadc4c19144c59da69e79991dfa85',\n",
       " 'text': 'My landlord is kicking me out of my home!',\n",
       " 'save-text': 0,\n",
       " 'cutoff-lower': 0.25,\n",
       " 'cutoff-pred': 0.5,\n",
       " 'cutoff-upper': 0.6,\n",
       " 'labels': [{'id': 'HE-00-00-00-00',\n",
       "   'name': 'Health',\n",
       "   'lower': 0.5921375904529399,\n",
       "   'pred': 0.7197019497018522,\n",
       "   'upper': 0.7721209698503828},\n",
       "  {'id': 'HO-00-00-00-00',\n",
       "   'name': 'Housing',\n",
       "   'lower': 0.6414757850122337,\n",
       "   'pred': 0.6943670230999232,\n",
       "   'upper': 0.7115290310801489,\n",
       "   'children': [{'id': 'HO-06-00-00-00',\n",
       "     'name': 'Renting or leasing a home',\n",
       "     'lower': 0.6968378623023264,\n",
       "     'pred': 0.8782301181508704,\n",
       "     'upper': 0.9036186628528304}]}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "spot(\"My landlord is kicking me out of my home!\", verbose=1)\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f1ce87",
   "metadata": {},
   "source": [
    "A function to pull words out of snake_case, camelCase and the like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bad0c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_case(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Capture PascalCase, snake_case and kebab-case terms and add spaces to separate the joined words\n",
    "    \"\"\"\n",
    "    re_outer = re.compile(r\"([^A-Z ])([A-Z])\")\n",
    "    re_inner = re.compile(r\"(?<!^)([A-Z])([^A-Z])\")\n",
    "    text = re_outer.sub(r\"\\1 \\2\", re_inner.sub(r\" \\1\\2\", text))\n",
    "    return text.replace(\"_\", \" \").replace(\"-\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8446113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deal with snake case, camel Case, and similarly formated text.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "re_case(\"Deal with snake_case, camelCase, and similarly-formated text.\")\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926cb7e3",
   "metadata": {},
   "source": [
    "Takes text from an auto-generated field name and uses regex to convert it into an Assembly Line standard field.\n",
    "See https://suffolklitlab.org/docassemble-AssemblyLine-documentation/docs/label_variables/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80db07f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_norm_field(text: str):\n",
    "    \"\"\"\n",
    "    Apply some heuristics to a field name to see if we can get it to match AssemblyLine conventions.\n",
    "    See: https://suffolklitlab.org/docassemble-AssemblyLine-documentation/docs/document_variables\n",
    "    \"\"\"\n",
    "    regex_list = [\n",
    "        # Personal info\n",
    "        ## Name & Bio\n",
    "        [\"^((My|Your|Full( legal)?) )?Name$\", \"users1_name\"],\n",
    "        [\"^(Typed or )?Printed Name\\s?\\d*$\", \"users1_name\"],\n",
    "        [\"^(DOB|Date of Birth|Birthday)$\", \"users1_birthdate\"],\n",
    "        ## Address\n",
    "        [\"^(Street )?Address$\", \"users1_address_line_one\"],\n",
    "        [\"^City State Zip$\", \"users1_address_line_two\"],\n",
    "        [\"^City$\", \"users1_address_city\"],\n",
    "        [\"^State$\", \"users1_address_state\"],\n",
    "        [\"^Zip( Code)?$\", \"users1_address_zip\"],\n",
    "        ## Contact\n",
    "        [\"^(Phone|Telephone)$\", \"users1_phone_number\"],\n",
    "        [\"^Email( Address)$\", \"users1_email\"],\n",
    "        # Parties\n",
    "        [\"^plaintiff\\(?s?\\)?$\", \"plaintiff1_name\"],\n",
    "        [\"^defendant\\(?s?\\)?$\", \"defendant1_name\"],\n",
    "        [\"^petitioner\\(?s?\\)?$\", \"petitioners1_name\"],\n",
    "        [\"^respondent\\(?s?\\)?$\", \"respondents1_name\"],\n",
    "        # Court info\n",
    "        [\"^(Court\\s)?Case\\s?(No|Number)?\\s?A?$\", \"docket_number\"],\n",
    "        [\"^file\\s?(No|Number)?\\s?A?$\", \"docket_number\"],\n",
    "        # Form info\n",
    "        [\"^(Signature|Sign( here)?)\\s?\\d*$\", \"users1_signature\"],\n",
    "        [\"^Date\\s?\\d*$\", \"signature_date\"],\n",
    "    ]\n",
    "    for regex in regex_list:\n",
    "        text = re.sub(regex[0], regex[1], text, flags=re.IGNORECASE)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd473f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'users1_name'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "regex_norm_field(\"Name\")\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bfed2fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_field(text: str, max_length: int = 30):\n",
    "    \"\"\"\n",
    "    Transforms a string of text into a snake_case variable close in length to `max_length` name by\n",
    "    summarizing the string and stitching the summary together in snake_case.\n",
    "    h/t https://towardsdatascience.com/nlp-building-a-summariser-68e0c19e3a93\n",
    "    \"\"\"\n",
    "    orig_title = text.lower()\n",
    "    orig_title = re.sub(\"[^a-zA-Z]+\", \" \", orig_title)\n",
    "    orig_title_words = orig_title.split()\n",
    "    deduped_sentence = []\n",
    "    for word in orig_title_words:\n",
    "        if word not in deduped_sentence:\n",
    "            deduped_sentence.append(word)\n",
    "    filtered_sentence = [w for w in deduped_sentence if not w.lower() in stop_words]\n",
    "    filtered_title_words = filtered_sentence\n",
    "    characters = len(\" \".join(filtered_title_words))\n",
    "    if characters > 0:\n",
    "        words = len(filtered_title_words)\n",
    "        av_word_len = math.ceil(\n",
    "            len(\" \".join(filtered_title_words)) / len(filtered_title_words)\n",
    "        )\n",
    "        x_words = math.floor((max_length) / av_word_len)\n",
    "        sim_mat = np.zeros([len(filtered_title_words), len(filtered_title_words)])\n",
    "        # for each word compared to other\n",
    "        for i in range(len(filtered_title_words)):\n",
    "            for j in range(len(filtered_title_words)):\n",
    "                if i != j:\n",
    "                    sim_mat[i][j] = cosine_similarity(\n",
    "                        nlp(filtered_title_words[i]).vector.reshape(1, 300),\n",
    "                        nlp(filtered_title_words[j]).vector.reshape(1, 300),\n",
    "                    )[0, 0]\n",
    "        try:\n",
    "            nx_graph = nx.from_numpy_array(sim_mat)\n",
    "            scores = nx.pagerank(nx_graph)\n",
    "            sorted_scores = sorted(\n",
    "                scores.items(), key=lambda item: item[1], reverse=True\n",
    "            )\n",
    "            if x_words > len(scores):\n",
    "                x_words = len(scores)\n",
    "            i = 0\n",
    "            new_title = \"\"\n",
    "            for x in filtered_title_words:\n",
    "                if scores[i] >= sorted_scores[x_words - 1][1]:\n",
    "                    if len(new_title) > 0:\n",
    "                        new_title += \"_\"\n",
    "                    new_title += x\n",
    "                i += 1\n",
    "            return new_title\n",
    "        except:\n",
    "            return \"_\".join(filtered_title_words)\n",
    "    else:\n",
    "        if re.search(\"^(\\d+)$\", text):\n",
    "            return \"unknown\"\n",
    "        else:\n",
    "            return re.sub(\"\\s+\", \"_\", text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea7d958d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'name_field_fill'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "reformat_field(\"this is a name field where you fill out your name\")\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "033eb6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(row):\n",
    "    \"\"\"Normalize a word vector.\"\"\"\n",
    "    try:\n",
    "        matrix = row.reshape(1, -1).astype(np.float64)\n",
    "        return normalize(matrix, axis=1, norm=\"l1\")[0]\n",
    "    except Exception as e:\n",
    "        print(\"===================\")\n",
    "        print(\"Error: \", e)\n",
    "        print(\"===================\")\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1168a20e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.50101741e-03,  8.06820327e-03, -3.11104546e-03, -8.06839202e-04,\n",
       "        9.36138759e-04,  3.32848476e-03,  1.45701220e-03, -7.19250437e-03,\n",
       "       -8.68764236e-03,  4.02694501e-02, -4.45449456e-03, -3.00806598e-04,\n",
       "       -6.94055298e-03, -6.98452887e-04, -8.21709334e-03, -6.33765801e-03,\n",
       "        1.34657817e-03,  3.99222299e-02, -2.91738078e-03,  2.73889565e-03,\n",
       "        2.30158149e-03,  8.75944408e-04, -1.06160408e-03, -1.12909651e-03,\n",
       "       -1.99027611e-03, -1.04073346e-03, -7.47178400e-03, -8.75291624e-05,\n",
       "       -3.82160381e-04, -3.46329858e-03, -2.59496260e-03,  3.65859045e-03,\n",
       "       -2.73836262e-04, -3.24242474e-03,  7.68538054e-03,  9.88163513e-04,\n",
       "        1.96531718e-03,  2.74642598e-03, -4.23523004e-03, -5.25741507e-03,\n",
       "       -2.13763885e-03,  6.30498847e-03, -7.16247274e-04, -4.61695256e-03,\n",
       "        3.06169596e-03,  3.01164526e-04, -9.31444687e-03, -8.76811481e-03,\n",
       "       -1.56148443e-03,  8.00177205e-03, -1.23142935e-03,  3.53072454e-03,\n",
       "        3.14601198e-03, -2.39086360e-03,  2.24703964e-03, -3.94186181e-03,\n",
       "       -2.04159819e-03,  2.46404335e-03,  4.36190688e-03,  1.02686864e-03,\n",
       "       -5.45658974e-03,  3.74560560e-03,  8.13738610e-04,  6.20759477e-03,\n",
       "        1.85292250e-03, -3.05740004e-03, -4.67620306e-03, -9.26472601e-04,\n",
       "        5.81793221e-04,  7.17242224e-04,  7.80741646e-03, -2.39707976e-03,\n",
       "        1.97730196e-03,  4.87405129e-03, -4.36178871e-05,  5.54757737e-03,\n",
       "        2.18215580e-03, -1.68420811e-03,  1.34476933e-03,  1.96272235e-03,\n",
       "        2.42524385e-03,  2.81968006e-04, -8.04242735e-04, -1.37668319e-03,\n",
       "       -1.58386075e-03, -1.28089092e-03,  1.53152641e-02,  4.78266345e-03,\n",
       "        7.17608726e-03,  1.77275348e-03,  6.46514528e-04, -1.08619090e-03,\n",
       "       -2.27150390e-03, -1.86060020e-03,  4.19176558e-03, -3.58001506e-04,\n",
       "        4.94642446e-03,  3.12891622e-03, -2.74127480e-03,  2.50648743e-04,\n",
       "       -9.25026359e-04,  1.59269599e-03, -4.24435023e-03,  2.62952835e-03,\n",
       "       -6.13850411e-03, -2.17120803e-02,  1.39759479e-03,  6.09184017e-04,\n",
       "        2.49725318e-03, -2.12191113e-03,  1.88062038e-03,  4.88609976e-04,\n",
       "        1.10142470e-03, -8.96151068e-03,  1.57635487e-03,  5.33846360e-03,\n",
       "        3.30331841e-03, -2.67112088e-03,  4.59505487e-04,  3.44750178e-03,\n",
       "       -8.97463261e-04,  2.42542736e-04,  1.14732430e-03,  2.12793623e-03,\n",
       "        6.97762140e-04,  1.26743173e-04,  1.01222282e-04, -4.87141334e-03,\n",
       "       -1.15293418e-03,  1.26316955e-03, -2.83130615e-03, -1.73997681e-05,\n",
       "       -1.70901901e-04, -6.39862316e-04, -1.34994619e-03, -4.22803770e-04,\n",
       "       -1.74127148e-03, -2.81567134e-03,  4.79511954e-04, -6.05616605e-03,\n",
       "       -4.62635046e-02,  5.77167223e-04, -1.49821845e-03,  1.43509034e-03,\n",
       "       -3.00911493e-03,  5.31466911e-04, -1.88215581e-03, -1.00099640e-04,\n",
       "        6.69491571e-03, -3.18604348e-03, -2.10894756e-03, -6.42238136e-04,\n",
       "       -2.65164655e-03,  3.74685624e-03,  2.60701069e-03, -1.44854513e-03,\n",
       "       -2.67881246e-04, -2.51784828e-03,  2.97018191e-03,  3.29713861e-03,\n",
       "        2.85819051e-03,  3.62383024e-04, -1.27251608e-02,  4.46828530e-03,\n",
       "       -7.43266083e-05, -9.75556380e-04,  2.12725857e-03, -4.13431988e-03,\n",
       "        8.61003929e-04,  3.91270355e-04, -9.48954462e-04, -1.26469699e-03,\n",
       "        2.00139948e-03,  1.26542372e-03, -6.56261360e-03,  7.34986103e-04,\n",
       "        1.65899404e-03,  2.05929560e-03,  8.04600462e-03, -4.28717206e-03,\n",
       "       -1.48185463e-03,  3.77501433e-04,  2.07958818e-04, -4.68295028e-04,\n",
       "       -1.99502862e-03,  8.74327690e-04,  4.25801169e-04, -1.69457281e-03,\n",
       "        1.62404406e-03,  2.56898294e-03, -3.24658271e-03,  1.73079730e-03,\n",
       "       -4.63545156e-03,  1.05840961e-03, -2.49927002e-03,  3.74314391e-03,\n",
       "       -4.03986507e-03, -3.13854264e-03,  2.11284385e-03, -3.85049708e-03,\n",
       "       -7.07719026e-04, -1.57870380e-03,  4.61250715e-03, -2.36517062e-03,\n",
       "        7.21559501e-03,  3.30330302e-03, -1.12509517e-03, -2.73685872e-04,\n",
       "        4.68598322e-03,  2.77988116e-04, -2.08945728e-03,  4.13842704e-03,\n",
       "        1.23932820e-04, -8.08974752e-04,  7.13315151e-03,  6.71910309e-03,\n",
       "       -6.69629124e-04,  5.92768213e-03, -3.85635325e-03, -5.76570271e-04,\n",
       "        2.29345413e-03,  1.51404151e-03,  2.29713684e-03,  1.72772936e-04,\n",
       "        1.95687330e-03,  5.01440110e-04, -7.70681260e-03,  3.90699073e-03,\n",
       "       -3.33437019e-03,  4.97434765e-03,  1.91641946e-03,  6.48351110e-05,\n",
       "        6.68519983e-04,  2.66229352e-03, -2.94558815e-03, -5.51314919e-03,\n",
       "       -1.00600061e-03, -2.15627946e-03, -4.22828329e-03,  6.16501809e-03,\n",
       "        5.58496171e-03,  6.34145742e-04,  2.79227708e-03, -1.33085728e-03,\n",
       "        4.09607509e-03, -3.47843195e-03, -9.71131161e-04, -8.83617763e-03,\n",
       "       -3.06667915e-03,  2.74913799e-03,  8.65552309e-03, -7.32383981e-03,\n",
       "       -3.70217768e-03, -1.51744273e-03, -3.38210766e-03,  5.94733480e-03,\n",
       "        3.74934719e-03,  2.33352046e-04,  5.00755670e-03,  2.82440924e-03,\n",
       "        3.74163851e-03,  3.58563005e-03, -3.27516817e-03,  4.99010827e-03,\n",
       "        1.15271869e-03,  1.00154047e-03, -2.45696712e-03, -2.29261215e-03,\n",
       "       -1.18966597e-03,  9.52615546e-03,  6.19728704e-03, -9.78901511e-04,\n",
       "        2.44715098e-03, -6.26059659e-03, -6.42795873e-03,  1.97439774e-03,\n",
       "        1.97242881e-03,  3.29362753e-03, -2.52103823e-03,  3.29824843e-03,\n",
       "        2.77461026e-03,  4.40552680e-03, -2.94909367e-03, -3.86621267e-03,\n",
       "        4.87882186e-04, -6.04063785e-03,  2.01400055e-03,  1.26026232e-04,\n",
       "       -3.94535404e-03, -5.06081288e-03,  4.87352149e-04, -3.10013237e-03,\n",
       "       -2.21226111e-03, -5.90989419e-04,  2.49808631e-03,  1.08049616e-03,\n",
       "       -4.29873699e-03, -6.22362209e-03, -2.28703151e-03,  4.65456935e-03])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "word_vector = np.array(\n",
    "    [\n",
    "        -2.13013589e-01,\n",
    "        3.12421650e-01,\n",
    "        -1.20467708e-01,\n",
    "        -3.12428959e-02,\n",
    "        3.62497084e-02,\n",
    "        1.28887519e-01,\n",
    "        5.64192720e-02,\n",
    "        -2.78512329e-01,\n",
    "        -3.36407930e-01,\n",
    "        1.55933702e00,\n",
    "        -1.72489524e-01,\n",
    "        -1.16480077e-02,\n",
    "        -2.68756121e-01,\n",
    "        -2.70458981e-02,\n",
    "        -3.18187058e-01,\n",
    "        -2.45410472e-01,\n",
    "        5.21429814e-02,\n",
    "        1.54589176e00,\n",
    "        -1.12968512e-01,\n",
    "        1.06057107e-01,\n",
    "        8.91231745e-02,\n",
    "        3.39188278e-02,\n",
    "        -4.11080495e-02,\n",
    "        -4.37215306e-02,\n",
    "        -7.70686269e-02,\n",
    "        -4.02998850e-02,\n",
    "        -2.89326757e-01,\n",
    "        -3.38935503e-03,\n",
    "        -1.47982361e-02,\n",
    "        -1.34107858e-01,\n",
    "        -1.00483648e-01,\n",
    "        1.41670063e-01,\n",
    "        -1.06036467e-02,\n",
    "        -1.25555053e-01,\n",
    "        2.97597766e-01,\n",
    "        3.82642411e-02,\n",
    "        7.61021525e-02,\n",
    "        1.06348701e-01,\n",
    "        -1.63999036e-01,\n",
    "        -2.03580678e-01,\n",
    "        -8.27748924e-02,\n",
    "        2.44145423e-01,\n",
    "        -2.77349427e-02,\n",
    "        -1.78780317e-01,\n",
    "        1.18556768e-01,\n",
    "        1.16618676e-02,\n",
    "        -3.60679418e-01,\n",
    "        -3.39524031e-01,\n",
    "        -6.04647063e-02,\n",
    "        3.09849262e-01,\n",
    "        -4.76841219e-02,\n",
    "        1.36718765e-01,\n",
    "        1.21821702e-01,\n",
    "        -9.25804079e-02,\n",
    "        8.70111734e-02,\n",
    "        -1.52639061e-01,\n",
    "        -7.90559500e-02,\n",
    "        9.54141170e-02,\n",
    "        1.68904290e-01,\n",
    "        3.97630036e-02,\n",
    "        -2.11293235e-01,\n",
    "        1.45039514e-01,\n",
    "        3.15100588e-02,\n",
    "        2.40374088e-01,\n",
    "        7.17499405e-02,\n",
    "        -1.18390419e-01,\n",
    "        -1.81074649e-01,\n",
    "        -3.58754098e-02,\n",
    "        2.25285348e-02,\n",
    "        2.77734697e-02,\n",
    "        3.02323312e-01,\n",
    "        -9.28211138e-02,\n",
    "        7.65662342e-02,\n",
    "        1.88735843e-01,\n",
    "        -1.68899714e-03,\n",
    "        2.14816511e-01,\n",
    "        8.44987035e-02,\n",
    "        -6.52168840e-02,\n",
    "        5.20729385e-02,\n",
    "        7.60016739e-02,\n",
    "        9.39117000e-02,\n",
    "        1.09185288e-02,\n",
    "        -3.11423540e-02,\n",
    "        -5.33087254e-02,\n",
    "        -6.13311753e-02,\n",
    "        -4.95994017e-02,\n",
    "        5.93046546e-01,\n",
    "        1.85197070e-01,\n",
    "        2.77876616e-01,\n",
    "        6.86455891e-02,\n",
    "        2.50347108e-02,\n",
    "        -4.20601144e-02,\n",
    "        -8.79584923e-02,\n",
    "        -7.20472410e-02,\n",
    "        1.62315980e-01,\n",
    "        -1.38627421e-02,\n",
    "        1.91538319e-01,\n",
    "        1.21159710e-01,\n",
    "        -1.06149234e-01,\n",
    "        9.70576610e-03,\n",
    "        -3.58194076e-02,\n",
    "        6.16732985e-02,\n",
    "        -1.64352193e-01,\n",
    "        1.01822123e-01,\n",
    "        -2.37698719e-01,\n",
    "        -8.40747774e-01,\n",
    "        5.41184768e-02,\n",
    "        2.35891771e-02,\n",
    "        9.67000872e-02,\n",
    "        -8.21658745e-02,\n",
    "        7.28224739e-02,\n",
    "        1.89202391e-02,\n",
    "        4.26500067e-02,\n",
    "        -3.47012818e-01,\n",
    "        6.10405281e-02,\n",
    "        2.06719086e-01,\n",
    "        1.27913013e-01,\n",
    "        -1.03432693e-01,\n",
    "        1.77932382e-02,\n",
    "        1.33496165e-01,\n",
    "        -3.47520933e-02,\n",
    "        9.39188059e-03,\n",
    "        4.44273576e-02,\n",
    "        8.23991820e-02,\n",
    "        2.70191506e-02,\n",
    "        4.90782270e-03,\n",
    "        3.91958794e-03,\n",
    "        -1.88633695e-01,\n",
    "        -4.46445867e-02,\n",
    "        4.89131846e-02,\n",
    "        -1.09635480e-01,\n",
    "        -6.73763920e-04,\n",
    "        -6.61776261e-03,\n",
    "        -2.47771200e-02,\n",
    "        -5.22734001e-02,\n",
    "        -1.63720530e-02,\n",
    "        -6.74265251e-02,\n",
    "        -1.09030060e-01,\n",
    "        1.85679402e-02,\n",
    "        -2.34510377e-01,\n",
    "        -1.79144228e00,\n",
    "        2.23494042e-02,\n",
    "        -5.80148846e-02,\n",
    "        5.55704013e-02,\n",
    "        -1.16520695e-01,\n",
    "        2.05797702e-02,\n",
    "        -7.28819296e-02,\n",
    "        -3.87611636e-03,\n",
    "        2.59244412e-01,\n",
    "        -1.23371825e-01,\n",
    "        -8.16638917e-02,\n",
    "        -2.48691179e-02,\n",
    "        -1.02678597e-01,\n",
    "        1.45087942e-01,\n",
    "        1.00950181e-01,\n",
    "        -5.60914055e-02,\n",
    "        -1.03730531e-02,\n",
    "        -9.74975824e-02,\n",
    "        1.15013108e-01,\n",
    "        1.27673715e-01,\n",
    "        1.10676512e-01,\n",
    "        1.40324058e-02,\n",
    "        -4.92751062e-01,\n",
    "        1.73023537e-01,\n",
    "        -2.87811807e-03,\n",
    "        -3.77760604e-02,\n",
    "        8.23729411e-02,\n",
    "        -1.60091534e-01,\n",
    "        3.33402939e-02,\n",
    "        1.51509978e-02,\n",
    "        -3.67459655e-02,\n",
    "        -4.89723310e-02,\n",
    "        7.74993524e-02,\n",
    "        4.90004718e-02,\n",
    "        -2.54121333e-01,\n",
    "        2.84605585e-02,\n",
    "        6.42405301e-02,\n",
    "        7.97412395e-02,\n",
    "        3.11562061e-01,\n",
    "        -1.66010365e-01,\n",
    "        -5.73812351e-02,\n",
    "        1.46178296e-02,\n",
    "        8.05270206e-03,\n",
    "        -1.81335919e-02,\n",
    "        -7.72526562e-02,\n",
    "        3.38562243e-02,\n",
    "        1.64881200e-02,\n",
    "        -6.56182319e-02,\n",
    "        6.28871769e-02,\n",
    "        9.94776487e-02,\n",
    "        -1.25716060e-01,\n",
    "        6.70209378e-02,\n",
    "        -1.79496646e-01,\n",
    "        4.09843512e-02,\n",
    "        -9.67781842e-02,\n",
    "        1.44944191e-01,\n",
    "        -1.56434000e-01,\n",
    "        -1.21532470e-01,\n",
    "        8.18147659e-02,\n",
    "        -1.49101183e-01,\n",
    "        -2.74047069e-02,\n",
    "        -6.11314848e-02,\n",
    "        1.78608179e-01,\n",
    "        -9.15855095e-02,\n",
    "        2.79406458e-01,\n",
    "        1.27912417e-01,\n",
    "        -4.35665883e-02,\n",
    "        -1.05978232e-02,\n",
    "        1.81453362e-01,\n",
    "        1.07644172e-02,\n",
    "        -8.09091777e-02,\n",
    "        1.60250574e-01,\n",
    "        4.79899859e-03,\n",
    "        -3.13255899e-02,\n",
    "        2.76214033e-01,\n",
    "        2.60181010e-01,\n",
    "        -2.59297676e-02,\n",
    "        2.29535148e-01,\n",
    "        -1.49327949e-01,\n",
    "        -2.23262887e-02,\n",
    "        8.88084620e-02,\n",
    "        5.86275943e-02,\n",
    "        8.89510661e-02,\n",
    "        6.69021392e-03,\n",
    "        7.57751837e-02,\n",
    "        1.94170550e-02,\n",
    "        -2.98427671e-01,\n",
    "        1.51288763e-01,\n",
    "        -1.29115418e-01,\n",
    "        1.92619577e-01,\n",
    "        7.42087066e-02,\n",
    "        2.51058280e-03,\n",
    "        2.58868188e-02,\n",
    "        1.03090875e-01,\n",
    "        -1.14060774e-01,\n",
    "        -2.13483363e-01,\n",
    "        -3.89549397e-02,\n",
    "        -8.34967047e-02,\n",
    "        -1.63730040e-01,\n",
    "        2.38725409e-01,\n",
    "        2.16264129e-01,\n",
    "        2.45557595e-02,\n",
    "        1.08124174e-01,\n",
    "        -5.15342280e-02,\n",
    "        1.58610597e-01,\n",
    "        -1.34693861e-01,\n",
    "        -3.76047045e-02,\n",
    "        -3.42159599e-01,\n",
    "        -1.18749730e-01,\n",
    "        1.06453717e-01,\n",
    "        3.35164189e-01,\n",
    "        -2.83597976e-01,\n",
    "        -1.43357873e-01,\n",
    "        -5.87592982e-02,\n",
    "        -1.30963936e-01,\n",
    "        2.30296150e-01,\n",
    "        1.45184398e-01,\n",
    "        9.03599337e-03,\n",
    "        1.93905517e-01,\n",
    "        1.09368414e-01,\n",
    "        1.44885898e-01,\n",
    "        1.38844848e-01,\n",
    "        -1.26822963e-01,\n",
    "        1.93229869e-01,\n",
    "        4.46362421e-02,\n",
    "        3.87822315e-02,\n",
    "        -9.51401070e-02,\n",
    "        -8.87758583e-02,\n",
    "        -4.60669361e-02,\n",
    "        3.68877321e-01,\n",
    "        2.39974946e-01,\n",
    "        -3.79055925e-02,\n",
    "        9.47600007e-02,\n",
    "        -2.42426455e-01,\n",
    "        -2.48907149e-01,\n",
    "        7.64537752e-02,\n",
    "        7.63775334e-02,\n",
    "        1.27537757e-01,\n",
    "        -9.76211056e-02,\n",
    "        1.27716690e-01,\n",
    "        1.07440069e-01,\n",
    "        1.70593366e-01,\n",
    "        -1.14196517e-01,\n",
    "        -1.49709731e-01,\n",
    "        1.88920572e-02,\n",
    "        -2.33909085e-01,\n",
    "        7.79872984e-02,\n",
    "        4.88006091e-03,\n",
    "        -1.52774289e-01,\n",
    "        -1.95967734e-01,\n",
    "        1.88715328e-02,\n",
    "        -1.20045125e-01,\n",
    "        -8.56644586e-02,\n",
    "        -2.28846353e-02,\n",
    "        9.67323482e-02,\n",
    "        4.18395996e-02,\n",
    "        -1.66458189e-01,\n",
    "        -2.40994707e-01,\n",
    "        -8.85597616e-02,\n",
    "        1.80236936e-01,\n",
    "    ]\n",
    ")\n",
    "\n",
    "norm(word_vector)\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73ad089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(text: str, normalize: bool = True):\n",
    "    \"\"\"Vectorize a string of text.\"\"\"\n",
    "    output = nlp(str(text)).vector\n",
    "    if normalize:\n",
    "        return norm(output)\n",
    "    else:\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b11cdfb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.50101742e-03,  8.06820326e-03, -3.11104545e-03, -8.06839201e-04,\n",
       "        9.36138759e-04,  3.32848477e-03,  1.45701220e-03, -7.19250437e-03,\n",
       "       -8.68764235e-03,  4.02694501e-02, -4.45449456e-03, -3.00806598e-04,\n",
       "       -6.94055299e-03, -6.98452888e-04, -8.21709334e-03, -6.33765801e-03,\n",
       "        1.34657817e-03,  3.99222300e-02, -2.91738078e-03,  2.73889566e-03,\n",
       "        2.30158149e-03,  8.75944407e-04, -1.06160408e-03, -1.12909651e-03,\n",
       "       -1.99027611e-03, -1.04073346e-03, -7.47178401e-03, -8.75291623e-05,\n",
       "       -3.82160381e-04, -3.46329858e-03, -2.59496261e-03,  3.65859045e-03,\n",
       "       -2.73836264e-04, -3.24242475e-03,  7.68538053e-03,  9.88163512e-04,\n",
       "        1.96531718e-03,  2.74642598e-03, -4.23523004e-03, -5.25741506e-03,\n",
       "       -2.13763885e-03,  6.30498847e-03, -7.16247275e-04, -4.61695257e-03,\n",
       "        3.06169595e-03,  3.01164527e-04, -9.31444686e-03, -8.76811480e-03,\n",
       "       -1.56148443e-03,  8.00177206e-03, -1.23142935e-03,  3.53072454e-03,\n",
       "        3.14601197e-03, -2.39086359e-03,  2.24703964e-03, -3.94186182e-03,\n",
       "       -2.04159819e-03,  2.46404335e-03,  4.36190687e-03,  1.02686864e-03,\n",
       "       -5.45658975e-03,  3.74560559e-03,  8.13738610e-04,  6.20759478e-03,\n",
       "        1.85292250e-03, -3.05740003e-03, -4.67620306e-03, -9.26472602e-04,\n",
       "        5.81793220e-04,  7.17242223e-04,  7.80741645e-03, -2.39707976e-03,\n",
       "        1.97730196e-03,  4.87405128e-03, -4.36178872e-05,  5.54757736e-03,\n",
       "        2.18215580e-03, -1.68420811e-03,  1.34476933e-03,  1.96272235e-03,\n",
       "        2.42524385e-03,  2.81968005e-04, -8.04242735e-04, -1.37668318e-03,\n",
       "       -1.58386075e-03, -1.28089092e-03,  1.53152641e-02,  4.78266345e-03,\n",
       "        7.17608724e-03,  1.77275348e-03,  6.46514527e-04, -1.08619090e-03,\n",
       "       -2.27150390e-03, -1.86060020e-03,  4.19176557e-03, -3.58001506e-04,\n",
       "        4.94642446e-03,  3.12891622e-03, -2.74127480e-03,  2.50648743e-04,\n",
       "       -9.25026358e-04,  1.59269599e-03, -4.24435024e-03,  2.62952835e-03,\n",
       "       -6.13850410e-03, -2.17120802e-02,  1.39759479e-03,  6.09184016e-04,\n",
       "        2.49725318e-03, -2.12191113e-03,  1.88062038e-03,  4.88609975e-04,\n",
       "        1.10142470e-03, -8.96151067e-03,  1.57635487e-03,  5.33846358e-03,\n",
       "        3.30331842e-03, -2.67112087e-03,  4.59505487e-04,  3.44750179e-03,\n",
       "       -8.97463260e-04,  2.42542736e-04,  1.14732430e-03,  2.12793623e-03,\n",
       "        6.97762139e-04,  1.26743173e-04,  1.01222281e-04, -4.87141335e-03,\n",
       "       -1.15293419e-03,  1.26316955e-03, -2.83130614e-03, -1.73997681e-05,\n",
       "       -1.70901901e-04, -6.39862315e-04, -1.34994620e-03, -4.22803769e-04,\n",
       "       -1.74127148e-03, -2.81567135e-03,  4.79511954e-04, -6.05616605e-03,\n",
       "       -4.62635045e-02,  5.77167222e-04, -1.49821845e-03,  1.43509034e-03,\n",
       "       -3.00911494e-03,  5.31466911e-04, -1.88215581e-03, -1.00099640e-04,\n",
       "        6.69491571e-03, -3.18604347e-03, -2.10894756e-03, -6.42238136e-04,\n",
       "       -2.65164655e-03,  3.74685625e-03,  2.60701070e-03, -1.44854513e-03,\n",
       "       -2.67881247e-04, -2.51784828e-03,  2.97018190e-03,  3.29713862e-03,\n",
       "        2.85819052e-03,  3.62383024e-04, -1.27251608e-02,  4.46828530e-03,\n",
       "       -7.43266084e-05, -9.75556380e-04,  2.12725857e-03, -4.13431988e-03,\n",
       "        8.61003929e-04,  3.91270355e-04, -9.48954462e-04, -1.26469699e-03,\n",
       "        2.00139948e-03,  1.26542372e-03, -6.56261361e-03,  7.34986103e-04,\n",
       "        1.65899404e-03,  2.05929560e-03,  8.04600463e-03, -4.28717206e-03,\n",
       "       -1.48185463e-03,  3.77501432e-04,  2.07958818e-04, -4.68295027e-04,\n",
       "       -1.99502862e-03,  8.74327689e-04,  4.25801168e-04, -1.69457281e-03,\n",
       "        1.62404406e-03,  2.56898295e-03, -3.24658272e-03,  1.73079730e-03,\n",
       "       -4.63545156e-03,  1.05840961e-03, -2.49927001e-03,  3.74314391e-03,\n",
       "       -4.03986505e-03, -3.13854264e-03,  2.11284385e-03, -3.85049708e-03,\n",
       "       -7.07719026e-04, -1.57870380e-03,  4.61250715e-03, -2.36517062e-03,\n",
       "        7.21559501e-03,  3.30330302e-03, -1.12509517e-03, -2.73685872e-04,\n",
       "        4.68598322e-03,  2.77988117e-04, -2.08945728e-03,  4.13842705e-03,\n",
       "        1.23932820e-04, -8.08974751e-04,  7.13315152e-03,  6.71910309e-03,\n",
       "       -6.69629125e-04,  5.92768212e-03, -3.85635324e-03, -5.76570272e-04,\n",
       "        2.29345413e-03,  1.51404151e-03,  2.29713684e-03,  1.72772936e-04,\n",
       "        1.95687330e-03,  5.01440109e-04, -7.70681261e-03,  3.90699073e-03,\n",
       "       -3.33437018e-03,  4.97434765e-03,  1.91641946e-03,  6.48351109e-05,\n",
       "        6.68519982e-04,  2.66229352e-03, -2.94558816e-03, -5.51314920e-03,\n",
       "       -1.00600061e-03, -2.15627946e-03, -4.22828330e-03,  6.16501809e-03,\n",
       "        5.58496170e-03,  6.34145742e-04,  2.79227709e-03, -1.33085728e-03,\n",
       "        4.09607509e-03, -3.47843195e-03, -9.71131161e-04, -8.83617763e-03,\n",
       "       -3.06667916e-03,  2.74913799e-03,  8.65552310e-03, -7.32383981e-03,\n",
       "       -3.70217768e-03, -1.51744273e-03, -3.38210767e-03,  5.94733479e-03,\n",
       "        3.74934718e-03,  2.33352046e-04,  5.00755671e-03,  2.82440923e-03,\n",
       "        3.74163850e-03,  3.58563004e-03, -3.27516818e-03,  4.99010827e-03,\n",
       "        1.15271869e-03,  1.00154047e-03, -2.45696712e-03, -2.29261215e-03,\n",
       "       -1.18966597e-03,  9.52615547e-03,  6.19728704e-03, -9.78901510e-04,\n",
       "        2.44715098e-03, -6.26059659e-03, -6.42795873e-03,  1.97439774e-03,\n",
       "        1.97242881e-03,  3.29362754e-03, -2.52103823e-03,  3.29824843e-03,\n",
       "        2.77461027e-03,  4.40552680e-03, -2.94909366e-03, -3.86621268e-03,\n",
       "        4.87882187e-04, -6.04063786e-03,  2.01400055e-03,  1.26026232e-04,\n",
       "       -3.94535404e-03, -5.06081288e-03,  4.87352148e-04, -3.10013238e-03,\n",
       "       -2.21226110e-03, -5.90989417e-04,  2.49808631e-03,  1.08049616e-03,\n",
       "       -4.29873701e-03, -6.22362208e-03, -2.28703151e-03,  4.65456934e-03])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "vectorize(\"how much wood would a wood chuck chuck, if a wood chuck could chuck wood?\")\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d84627",
   "metadata": {},
   "source": [
    "Given an auto-generated field name and context from the form where it appeared, this function attempts to normalize the field name. Here's what's going on:\n",
    "1. It will `re_case` the variable text\n",
    "2. Then it will run the output through `regex_norm_field`\n",
    "3. If it doesn't find anything, it will use the ML model `clf_field_names`\n",
    "4. If the prediction isn't very confident, it will run it through `reformat_field`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1dccc3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_name(jur: str, group: str, n: int, per, last_field: str, this_field: str):\n",
    "    \"\"\"Add hard coded conversions maybe by calling a function\n",
    "    if returns 0 then fail over to ML or other way around poor prob -> check hard-coded\n",
    "    \"\"\"\n",
    "    if this_field not in included_fields:\n",
    "        this_field = re_case(this_field)\n",
    "        out_put = regex_norm_field(this_field)\n",
    "        conf = 1.0\n",
    "        if out_put == this_field:\n",
    "            params = []\n",
    "            for item in jurisdictions:\n",
    "                if jur == item:\n",
    "                    params.append(1)\n",
    "                else:\n",
    "                    params.append(0)\n",
    "            for item in groups:\n",
    "                if group == item:\n",
    "                    params.append(1)\n",
    "                else:\n",
    "                    params.append(0)\n",
    "            params.append(n)\n",
    "            params.append(per)\n",
    "            for vec in vectorize(this_field):\n",
    "                params.append(vec)\n",
    "            for item in included_fields:\n",
    "                if last_field == item:\n",
    "                    params.append(1)\n",
    "                else:\n",
    "                    params.append(0)\n",
    "            pred = clf_field_names.predict([params])\n",
    "            prob = clf_field_names.predict_proba([params])\n",
    "            conf = prob[0].tolist()[prob[0].tolist().index(max(prob[0].tolist()))]\n",
    "            out_put = pred[0]\n",
    "    else:\n",
    "        out_put = this_field\n",
    "        conf = 1\n",
    "    if out_put in included_fields:\n",
    "        if conf >= 0:\n",
    "            return (\n",
    "                \"*\" + out_put,\n",
    "                conf,\n",
    "            )  # this * is a hack to show when something is in the list of known fields later. I need to fix this\n",
    "        else:\n",
    "            return reformat_field(this_field), conf\n",
    "    else:\n",
    "        return reformat_field(this_field), conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36ebb202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('name_thing', 0.38)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "normalize_name(\"UT\", None, 2, 0.3, \"null\", \"Name thing\")\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdec9dc",
   "metadata": {},
   "source": [
    "Take a list of AL variables and spits out suggested groupings. Here's what's going on:\n",
    "\n",
    "1. It reads in a list of fields (e.g., `[\"user_name\",\"user_address\"]`)\n",
    "2. Splits each field into words (e.g., turning `user_name` into `user name`)\n",
    "3. It then turns these ngrams/\"sentences\" into vectors using word2vec. \n",
    "4. For the collection of fields, it finds clusters of these \"sentences\" within the semantic space defined by word2vec. Currently it uses Affinity Propagation. See https://machinelearningmastery.com/clustering-algorithms-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37f7b31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_screens(fields: List[str] = [], damping: float = 0.7):\n",
    "    \"\"\"Takes in a list (fields) and returns a suggested screen grouping\n",
    "    Set damping to value >= 0.5 or < 1 to tune how related screens should be\"\"\"\n",
    "    vec_mat = np.zeros([len(fields), 300])\n",
    "    for i in range(len(fields)):\n",
    "        vec_mat[i] = [nlp(re_case(fields[i])).vector][0]\n",
    "    # create model\n",
    "    model = AffinityPropagation(damping=damping, random_state=None)\n",
    "    # model = AffinityPropagation(damping=damping,random_state=4) consider using this to get consistent results. note will have to require newer version\n",
    "    # fit the model\n",
    "    model.fit(vec_mat)\n",
    "    # assign a cluster to each example\n",
    "    yhat = model.predict(vec_mat)\n",
    "    # retrieve unique clusters\n",
    "    clusters = unique(yhat)\n",
    "    screens = {}\n",
    "    # sim = np.zeros([5,300])\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        this_screen = where(yhat == cluster)[0]\n",
    "        vars = []\n",
    "        for screen in this_screen:\n",
    "            # sim[screen]=vec_mat[screen] # use this spot to add up vectors for compare to list\n",
    "            vars.append(fields[screen])\n",
    "        screens[\"screen_%s\" % i] = vars\n",
    "    return screens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed108360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'screen_0': ['users1_name',\n",
       "  'users1_address_line_one',\n",
       "  'users1_address_line_two',\n",
       "  'users1_address_city',\n",
       "  'users1_address_state',\n",
       "  'users1_address_zip',\n",
       "  'users1_phone_number',\n",
       "  'users1_email',\n",
       "  'plantiffs1_name',\n",
       "  'defendants1_name',\n",
       "  'petitioners1_name',\n",
       "  'respondents1_name'],\n",
       " 'screen_1': ['users1_birthdate'],\n",
       " 'screen_2': ['docket_number'],\n",
       " 'screen_3': ['trial_court_county'],\n",
       " 'screen_4': ['users1_signature', 'signature_date']}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "fields = [\n",
    "    \"users1_name\",\n",
    "    \"users1_birthdate\",\n",
    "    \"users1_address_line_one\",\n",
    "    \"users1_address_line_two\",\n",
    "    \"users1_address_city\",\n",
    "    \"users1_address_state\",\n",
    "    \"users1_address_zip\",\n",
    "    \"users1_phone_number\",\n",
    "    \"users1_email\",\n",
    "    \"plantiffs1_name\",\n",
    "    \"defendants1_name\",\n",
    "    \"petitioners1_name\",\n",
    "    \"respondents1_name\",\n",
    "    \"docket_number\",\n",
    "    \"trial_court_county\",\n",
    "    \"users1_signature\",\n",
    "    \"signature_date\",\n",
    "]\n",
    "\n",
    "cluster_screens(fields, damping=0.7)\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ed72f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000000000007, 1.0000000000000007, 1.0000000000000007, 1.0000000000000007, 1.0000000000000007]\n",
      "[0.3621327550226753, 0.3621327550226753, 0.3621327550226753, 0.3621327550226753, 0.3621327550226753]\n",
      "[0.578911480137959, 0.578911480137959, 0.578911480137959, 0.578911480137959, 0.578911480137959]\n",
      "[0.5249505877573547, 0.5249505877573547, 0.5249505877573547, 0.5249505877573547, 0.5249505877573547]\n",
      "[0.47429915019123686, 0.47429915019123686, 0.47429915019123686, 0.47429915019123686, 0.47429915019123686]\n",
      "[0.4378032607006819, 0.4378032607006819, 0.4378032607006819, 0.4378032607006819, 0.4378032607006819]\n",
      "[0.38390797350515915, 0.38390797350515915, 0.38390797350515915, 0.38390797350515915, 0.38390797350515915]\n",
      "[0.39353479206461484, 0.39353479206461484, 0.39353479206461484, 0.39353479206461484, 0.39353479206461484]\n",
      "[0.45157043557737164, 0.45157043557737164, 0.45157043557737164, 0.45157043557737164, 0.45157043557737164]\n",
      "[1.0000000000000007, 1.0000000000000007, 1.0000000000000007, 1.0000000000000007, 1.0000000000000007]\n",
      "[1.0000000000000007, 1.0000000000000007, 1.0000000000000007, 1.0000000000000007, 1.0000000000000007]\n",
      "[1.0000000000000007, 1.0000000000000007, 1.0000000000000007, 1.0000000000000007, 1.0000000000000007]\n",
      "[1.0000000000000007, 1.0000000000000007, 1.0000000000000007, 1.0000000000000007, 1.0000000000000007]\n",
      "[0.3206370159015671, 0.3206370159015671, 0.3206370159015671, 0.3206370159015671, 0.3206370159015671]\n",
      "[0.24754157879262495, 0.24754157879262495, 0.24754157879262495, 0.24754157879262495, 0.24754157879262495]\n",
      "[0.41985908132418404, 0.41985908132418404, 0.41985908132418404, 0.41985908132418404, 0.41985908132418404]\n",
      "[0.5281231949435532, 0.5281231949435532, 0.5281231949435532, 0.5281231949435532, 0.5281231949435532]\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "vec_mat = np.zeros([len(fields), 300])\n",
    "for i in range(len(fields)):\n",
    "    vec_mat[i] = [nlp(re_case(fields[i])).vector][0]\n",
    "\n",
    "parts = np.zeros([5, 300])\n",
    "\n",
    "for row in vec_mat:\n",
    "    sim = []\n",
    "    for part in parts:\n",
    "        sim.append(\n",
    "            cosine_similarity(vec_mat[0].reshape(1, -1), row.reshape(1, -1))[0][0]\n",
    "        )\n",
    "    print(sim)\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ddfc0892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_existing_pdf_fields(\n",
    "    in_file: Union[str, Path, BinaryIO, pikepdf.Pdf]\n",
    ") -> Iterable:\n",
    "    \"\"\"\n",
    "    Use PikePDF to get fields from the PDF\n",
    "    \"\"\"\n",
    "    if isinstance(in_file, pikepdf.Pdf):\n",
    "        in_pdf = in_file\n",
    "    else:\n",
    "        in_pdf = pikepdf.Pdf.open(in_file)\n",
    "    return [\n",
    "        {\"type\": str(field.FT), \"var_name\": str(field.T), \"all\": field}\n",
    "        for field in iter(in_pdf.Root.AcroForm.Fields)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42fddf00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': '/Btn',\n",
       "  'var_name': 'moving party',\n",
       "  'all': <pikepdf.Dictionary(Type=\"/Annot\")({\n",
       "    \"/AP\": {\n",
       "      \"/D\": {\n",
       "        \"/Off\": pikepdf.Stream(owner=<...>, data=<...>, {\n",
       "            \"/BBox\": [ Decimal('0.0'), Decimal('0.0'), Decimal('9.12'), Decimal('9.12') ],\n",
       "            \"/FormType\": 1,\n",
       "            \"/Length\": 30,\n",
       "            \"/Matrix\": [ Decimal('1.0'), Decimal('0.0'), Decimal('0.0'), Decimal('1.0'), Decimal('0.0'), Decimal('0.0') ],\n",
       "            \"/Resources\": {\n",
       "              \"/ProcSet\": [ \"/PDF\" ]\n",
       "            },\n",
       "            \"/Subtype\": \"/Form\",\n",
       "            \"/Type\": \"/XObject\"\n",
       "          }),\n",
       "        \"/On\": pikepdf.Stream(owner=<...>, data=<...>, {\n",
       "            \"/BBox\": [ Decimal('0.0'), Decimal('0.0'), Decimal('9.12'), Decimal('9.12') ],\n",
       "            \"/Filter\": \"/FlateDecode\",\n",
       "            \"/FormType\": 1,\n",
       "            \"/Length\": 113,\n",
       "            \"/Matrix\": [ Decimal('1.0'), Decimal('0.0'), Decimal('0.0'), Decimal('1.0'), Decimal('0.0'), Decimal('0.0') ],\n",
       "            \"/Resources\": {\n",
       "              \"/Font\": {\n",
       "                \"/ZaDb\": {\n",
       "                  \"/BaseFont\": \"/ZapfDingbats\",\n",
       "                  \"/Name\": \"/ZaDb\",\n",
       "                  \"/Subtype\": \"/Type1\",\n",
       "                  \"/Type\": \"/Font\"\n",
       "                }\n",
       "              },\n",
       "              \"/ProcSet\": [ \"/PDF\", \"/Text\" ]\n",
       "            },\n",
       "            \"/Subtype\": \"/Form\",\n",
       "            \"/Type\": \"/XObject\"\n",
       "          })\n",
       "      },\n",
       "      \"/N\": {\n",
       "        \"/On\": pikepdf.Stream(owner=<...>, data=<...>, {\n",
       "            \"/BBox\": [ Decimal('0.0'), Decimal('0.0'), Decimal('9.12'), Decimal('9.12') ],\n",
       "            \"/FormType\": 1,\n",
       "            \"/Length\": 88,\n",
       "            \"/Matrix\": [ Decimal('1.0'), Decimal('0.0'), Decimal('0.0'), Decimal('1.0'), Decimal('0.0'), Decimal('0.0') ],\n",
       "            \"/Resources\": {\n",
       "              \"/Font\": {\n",
       "                \"/ZaDb\": <.get_object(62, 0)>\n",
       "              },\n",
       "              \"/ProcSet\": [ \"/PDF\", \"/Text\" ]\n",
       "            },\n",
       "            \"/Subtype\": \"/Form\",\n",
       "            \"/Type\": \"/XObject\"\n",
       "          })\n",
       "      }\n",
       "    },\n",
       "    \"/AS\": \"/Off\",\n",
       "    \"/F\": 4,\n",
       "    \"/FT\": \"/Btn\",\n",
       "    \"/MK\": {\n",
       "      \"/CA\": \"4\"\n",
       "    },\n",
       "    \"/P\": <Pdf.pages.from_objgen(16, 0)>,\n",
       "    \"/Rect\": [ Decimal('236.797'), Decimal('624.15'), Decimal('245.917'), Decimal('633.27') ],\n",
       "    \"/Subtype\": \"/Widget\",\n",
       "    \"/T\": \"moving party\",\n",
       "    \"/Type\": \"/Annot\"\n",
       "  })>},\n",
       " {'type': '/Btn',\n",
       "  'var_name': 'moving party_2',\n",
       "  'all': <pikepdf.Dictionary(Type=\"/Annot\")({\n",
       "    \"/AP\": {\n",
       "      \"/D\": {\n",
       "        \"/Off\": pikepdf.Stream(owner=<...>, data=<...>, {\n",
       "            \"/BBox\": [ Decimal('0.0'), Decimal('0.0'), Decimal('9.12'), Decimal('9.12') ],\n",
       "            \"/FormType\": 1,\n",
       "            \"/Length\": 30,\n",
       "            \"/Matrix\": [ Decimal('1.0'), Decimal('0.0'), Decimal('0.0'), Decimal('1.0'), Decimal('0.0'), Decimal('0.0') ],\n",
       "            \"/Resources\": {\n",
       "              \"/ProcSet\": [ \"/PDF\" ]\n",
       "            },\n",
       "            \"/Subtype\": \"/Form\",\n",
       "            \"/Type\": \"/XObject\"\n",
       "          }),\n",
       "        \"/On\": pikepdf.Stream(owner=<...>, data=<...>, {\n",
       "            \"/BBox\": [ Decimal('0.0'), Decimal('0.0'), Decimal('9.12'), Decimal('9.12') ],\n",
       "            \"/Filter\": \"/FlateDecode\",\n",
       "            \"/FormType\": 1,\n",
       "            \"/Length\": 113,\n",
       "            \"/Matrix\": [ Decimal('1.0'), Decimal('0.0'), Decimal('0.0'), Decimal('1.0'), Decimal('0.0'), Decimal('0.0') ],\n",
       "            \"/Resources\": {\n",
       "              \"/Font\": {\n",
       "                \"/ZaDb\": {\n",
       "                  \"/BaseFont\": \"/ZapfDingbats\",\n",
       "                  \"/Name\": \"/ZaDb\",\n",
       "                  \"/Subtype\": \"/Type1\",\n",
       "                  \"/Type\": \"/Font\"\n",
       "                }\n",
       "              },\n",
       "              \"/ProcSet\": [ \"/PDF\", \"/Text\" ]\n",
       "            },\n",
       "            \"/Subtype\": \"/Form\",\n",
       "            \"/Type\": \"/XObject\"\n",
       "          })\n",
       "      },\n",
       "      \"/N\": {\n",
       "        \"/On\": pikepdf.Stream(owner=<...>, data=<...>, {\n",
       "            \"/BBox\": [ Decimal('0.0'), Decimal('0.0'), Decimal('9.12'), Decimal('9.12') ],\n",
       "            \"/FormType\": 1,\n",
       "            \"/Length\": 88,\n",
       "            \"/Matrix\": [ Decimal('1.0'), Decimal('0.0'), Decimal('0.0'), Decimal('1.0'), Decimal('0.0'), Decimal('0.0') ],\n",
       "            \"/Resources\": {\n",
       "              \"/Font\": {\n",
       "                \"/ZaDb\": <.get_object(59, 0)>\n",
       "              },\n",
       "              \"/ProcSet\": [ \"/PDF\", \"/Text\" ]\n",
       "            },\n",
       "            \"/Subtype\": \"/Form\",\n",
       "            \"/Type\": \"/XObject\"\n",
       "          })\n",
       "      }\n",
       "    },\n",
       "    \"/AS\": \"/Off\",\n",
       "    \"/F\": 4,\n",
       "    \"/FT\": \"/Btn\",\n",
       "    \"/MK\": {\n",
       "      \"/CA\": \"4\"\n",
       "    },\n",
       "    \"/P\": <Pdf.pages.from_objgen(16, 0)>,\n",
       "    \"/Rect\": [ Decimal('522.037'), Decimal('623.55'), Decimal('531.157'), Decimal('632.67') ],\n",
       "    \"/Subtype\": \"/Widget\",\n",
       "    \"/T\": \"moving party_2\",\n",
       "    \"/Type\": \"/Annot\"\n",
       "  })>},\n",
       " {'type': '/Btn',\n",
       "  'var_name': 'moving party_3',\n",
       "  'all': <pikepdf.Dictionary(Type=\"/Annot\")({\n",
       "    \"/AP\": {\n",
       "      \"/D\": {\n",
       "        \"/Off\": pikepdf.Stream(owner=<...>, data=<...>, {\n",
       "            \"/BBox\": [ Decimal('0.0'), Decimal('0.0'), Decimal('9.0'), Decimal('9.0') ],\n",
       "            \"/FormType\": 1,\n",
       "            \"/Length\": 24,\n",
       "            \"/Matrix\": [ Decimal('1.0'), Decimal('0.0'), Decimal('0.0'), Decimal('1.0'), Decimal('0.0'), Decimal('0.0') ],\n",
       "            \"/Resources\": {\n",
       "              \"/ProcSet\": [ \"/PDF\" ]\n",
       "            },\n",
       "            \"/Subtype\": \"/Form\",\n",
       "            \"/Type\": \"/XObject\"\n",
       "          }),\n",
       "        \"/On\": pikepdf.Stream(owner=<...>, data=<...>, {\n",
       "            \"/BBox\": [ Decimal('0.0'), Decimal('0.0'), Decimal('9.0'), Decimal('9.0') ],\n",
       "            \"/FormType\": 1,\n",
       "            \"/Length\": 103,\n",
       "            \"/Matrix\": [ Decimal('1.0'), Decimal('0.0'), Decimal('0.0'), Decimal('1.0'), Decimal('0.0'), Decimal('0.0') ],\n",
       "            \"/Resources\": {\n",
       "              \"/Font\": {\n",
       "                \"/ZaDb\": {\n",
       "                  \"/BaseFont\": \"/ZapfDingbats\",\n",
       "                  \"/Name\": \"/ZaDb\",\n",
       "                  \"/Subtype\": \"/Type1\",\n",
       "                  \"/Type\": \"/Font\"\n",
       "                }\n",
       "              },\n",
       "              \"/ProcSet\": [ \"/PDF\", \"/Text\" ]\n",
       "            },\n",
       "            \"/Subtype\": \"/Form\",\n",
       "            \"/Type\": \"/XObject\"\n",
       "          })\n",
       "      },\n",
       "      \"/N\": {\n",
       "        \"/On\": pikepdf.Stream(owner=<...>, data=<...>, {\n",
       "            \"/BBox\": [ Decimal('0.0'), Decimal('0.0'), Decimal('9.0'), Decimal('9.0') ],\n",
       "            \"/FormType\": 1,\n",
       "            \"/Length\": 75,\n",
       "            \"/Matrix\": [ Decimal('1.0'), Decimal('0.0'), Decimal('0.0'), Decimal('1.0'), Decimal('0.0'), Decimal('0.0') ],\n",
       "            \"/Resources\": {\n",
       "              \"/Font\": {\n",
       "                \"/ZaDb\": <.get_object(54, 0)>\n",
       "              },\n",
       "              \"/ProcSet\": [ \"/PDF\", \"/Text\" ]\n",
       "            },\n",
       "            \"/Subtype\": \"/Form\",\n",
       "            \"/Type\": \"/XObject\"\n",
       "          })\n",
       "      }\n",
       "    },\n",
       "    \"/AS\": \"/Off\",\n",
       "    \"/F\": 4,\n",
       "    \"/FT\": \"/Btn\",\n",
       "    \"/MK\": {\n",
       "      \"/CA\": \"4\"\n",
       "    },\n",
       "    \"/P\": <Pdf.pages.from_objgen(16, 0)>,\n",
       "    \"/Rect\": [ Decimal('236.917'), Decimal('552.15'), Decimal('245.917'), Decimal('561.15') ],\n",
       "    \"/Subtype\": \"/Widget\",\n",
       "    \"/T\": \"moving party_3\",\n",
       "    \"/Type\": \"/Annot\"\n",
       "  })>},\n",
       " {'type': '/Tx',\n",
       "  'var_name': 'Date',\n",
       "  'all': pikepdf.Dictionary(Type=\"/Annot\")({\n",
       "    \"/AA\": {\n",
       "  \n",
       "    },\n",
       "    \"/DA\": \"/Helv 10 Tf 0 g\",\n",
       "    \"/F\": 4,\n",
       "    \"/FT\": \"/Tx\",\n",
       "    \"/Ff\": 8388608,\n",
       "    \"/MK\": {\n",
       "  \n",
       "    },\n",
       "    \"/P\": <Pdf.pages.from_objgen(16, 0)>,\n",
       "    \"/Rect\": [ Decimal('47.7971'), Decimal('191.75'), Decimal('163.837'), Decimal('208.463') ],\n",
       "    \"/Subtype\": \"/Widget\",\n",
       "    \"/T\": \"Date\",\n",
       "    \"/Type\": \"/Annot\"\n",
       "  })},\n",
       " {'type': '/Tx',\n",
       "  'var_name': 'Name type or print',\n",
       "  'all': pikepdf.Dictionary(Type=\"/Annot\")({\n",
       "    \"/DA\": \"/Helv 10 Tf 0 g\",\n",
       "    \"/F\": 4,\n",
       "    \"/FT\": \"/Tx\",\n",
       "    \"/Ff\": 8388608,\n",
       "    \"/MK\": {\n",
       "  \n",
       "    },\n",
       "    \"/P\": <Pdf.pages.from_objgen(16, 0)>,\n",
       "    \"/Rect\": [ Decimal('311.797'), Decimal('166.31'), Decimal('584.797'), Decimal('182.27') ],\n",
       "    \"/Subtype\": \"/Widget\",\n",
       "    \"/T\": \"Name type or print\",\n",
       "    \"/Type\": \"/Annot\"\n",
       "  })},\n",
       " {'type': '/Tx',\n",
       "  'var_name': 'Date_2',\n",
       "  'all': pikepdf.Dictionary(Type=\"/Annot\")({\n",
       "    \"/AA\": {\n",
       "  \n",
       "    },\n",
       "    \"/DA\": \"/Helv 10 Tf 0 g\",\n",
       "    \"/F\": 4,\n",
       "    \"/FT\": \"/Tx\",\n",
       "    \"/Ff\": 8388608,\n",
       "    \"/MK\": {\n",
       "  \n",
       "    },\n",
       "    \"/P\": <Pdf.pages.from_objgen(16, 0)>,\n",
       "    \"/Rect\": [ Decimal('47.7971'), Decimal('59.2701'), Decimal('163.837'), Decimal('77.932') ],\n",
       "    \"/Subtype\": \"/Widget\",\n",
       "    \"/T\": \"Date_2\",\n",
       "    \"/Type\": \"/Annot\"\n",
       "  })},\n",
       " {'type': '/Tx',\n",
       "  'var_name': 'CASE NO',\n",
       "  'all': pikepdf.Dictionary(Type=\"/Annot\")({\n",
       "    \"/DA\": \"/Helv 10 Tf 0 g\",\n",
       "    \"/F\": 4,\n",
       "    \"/FT\": \"/Tx\",\n",
       "    \"/Ff\": 8392704,\n",
       "    \"/MK\": {\n",
       "  \n",
       "    },\n",
       "    \"/P\": <Pdf.pages.from_objgen(16, 0)>,\n",
       "    \"/Rect\": [ Decimal('435.489'), Decimal('696.461'), Decimal('583.717'), Decimal('714.097') ],\n",
       "    \"/Subtype\": \"/Widget\",\n",
       "    \"/T\": \"CASE NO\",\n",
       "    \"/Type\": \"/Annot\"\n",
       "  })},\n",
       " {'type': '/Tx',\n",
       "  'var_name': 'judge',\n",
       "  'all': pikepdf.Dictionary(Type=\"/Annot\")({\n",
       "    \"/DA\": \"/Helv 10 Tf 0 g\",\n",
       "    \"/F\": 4,\n",
       "    \"/FT\": \"/Tx\",\n",
       "    \"/Ff\": 8392704,\n",
       "    \"/MK\": {\n",
       "  \n",
       "    },\n",
       "    \"/P\": <Pdf.pages.from_objgen(16, 0)>,\n",
       "    \"/Rect\": [ Decimal('436.216'), Decimal('678.283'), Decimal('584.444'), Decimal('695.919') ],\n",
       "    \"/Subtype\": \"/Widget\",\n",
       "    \"/T\": \"judge\",\n",
       "    \"/Type\": \"/Annot\"\n",
       "  })},\n",
       " {'type': '/Tx',\n",
       "  'var_name': 'circuit',\n",
       "  'all': pikepdf.Dictionary(Type=\"/Annot\")({\n",
       "    \"/DA\": \"/Helv 10 Tf 0 g\",\n",
       "    \"/F\": 4,\n",
       "    \"/FT\": \"/Tx\",\n",
       "    \"/Ff\": 8388608,\n",
       "    \"/MK\": {\n",
       "  \n",
       "    },\n",
       "    \"/P\": <Pdf.pages.from_objgen(16, 0)>,\n",
       "    \"/Rect\": [ Decimal('30.318'), Decimal('704.579'), Decimal('87.882'), Decimal('717.817') ],\n",
       "    \"/Subtype\": \"/Widget\",\n",
       "    \"/T\": \"circuit\",\n",
       "    \"/Type\": \"/Annot\"\n",
       "  })},\n",
       " {'type': '/Tx',\n",
       "  'var_name': 'county',\n",
       "  'all': pikepdf.Dictionary(Type=\"/Annot\")({\n",
       "    \"/DA\": \"/Helv 10 Tf 0 g\",\n",
       "    \"/F\": 4,\n",
       "    \"/FT\": \"/Tx\",\n",
       "    \"/Ff\": 8388608,\n",
       "    \"/MK\": {\n",
       "  \n",
       "    },\n",
       "    \"/P\": <Pdf.pages.from_objgen(16, 0)>,\n",
       "    \"/Rect\": [ Decimal('30.8849'), Decimal('691.17'), Decimal('136.765'), Decimal('704.408') ],\n",
       "    \"/Subtype\": \"/Widget\",\n",
       "    \"/T\": \"county\",\n",
       "    \"/Type\": \"/Annot\"\n",
       "  })},\n",
       " {'type': '/Tx',\n",
       "  'var_name': 'address',\n",
       "  'all': pikepdf.Dictionary(Type=\"/Annot\")({\n",
       "    \"/DA\": \"/Helv 10 Tf 0 g\",\n",
       "    \"/F\": 4,\n",
       "    \"/FT\": \"/Tx\",\n",
       "    \"/Ff\": 8388608,\n",
       "    \"/MK\": {\n",
       "  \n",
       "    },\n",
       "    \"/P\": <Pdf.pages.from_objgen(16, 0)>,\n",
       "    \"/Rect\": [ Decimal('27.8063'), Decimal('646.73'), Decimal('443.194'), Decimal('668.73') ],\n",
       "    \"/Subtype\": \"/Widget\",\n",
       "    \"/T\": \"address\",\n",
       "    \"/Type\": \"/Annot\"\n",
       "  })},\n",
       " {'type': '/Tx',\n",
       "  'var_name': 'telno',\n",
       "  'all': pikepdf.Dictionary(Type=\"/Annot\")({\n",
       "    \"/AA\": {\n",
       "  \n",
       "    },\n",
       "    \"/DA\": \"/Helv 10 Tf 0 g\",\n",
       "    \"/F\": 4,\n",
       "    \"/FT\": \"/Tx\",\n",
       "    \"/Ff\": 8388608,\n",
       "    \"/MK\": {\n",
       "  \n",
       "    },\n",
       "    \"/P\": <Pdf.pages.from_objgen(16, 0)>,\n",
       "    \"/Rect\": [ Decimal('446.544'), Decimal('646.029'), Decimal('596.544'), Decimal('668.029') ],\n",
       "    \"/Subtype\": \"/Widget\",\n",
       "    \"/T\": \"telno\",\n",
       "    \"/Type\": \"/Annot\"\n",
       "  })},\n",
       " {'type': '/Tx',\n",
       "  'var_name': 'Plaintiffs name address and telephone',\n",
       "  'all': pikepdf.Dictionary(Type=\"/Annot\")({\n",
       "    \"/DA\": \"/Helv 10 Tf 0 g\",\n",
       "    \"/F\": 4,\n",
       "    \"/FT\": \"/Tx\",\n",
       "    \"/Ff\": 8392704,\n",
       "    \"/MK\": {\n",
       "  \n",
       "    },\n",
       "    \"/P\": <Pdf.pages.from_objgen(16, 0)>,\n",
       "    \"/Rect\": [ Decimal('49.2371'), Decimal('563.63'), Decimal('298.357'), Decimal('622.07') ],\n",
       "    \"/Subtype\": \"/Widget\",\n",
       "    \"/T\": \"Plaintiffs name address and telephone\",\n",
       "    \"/Type\": \"/Annot\"\n",
       "  })},\n",
       " {'type': '/Tx',\n",
       "  'var_name': 'Defendants name address and telephone',\n",
       "  'all': pikepdf.Dictionary(Type=\"/Annot\")({\n",
       "    \"/DA\": \"/Helv 10 Tf 0 g\",\n",
       "    \"/F\": 4,\n",
       "    \"/FT\": \"/Tx\",\n",
       "    \"/Ff\": 8392704,\n",
       "    \"/MK\": {\n",
       "  \n",
       "    },\n",
       "    \"/P\": <Pdf.pages.from_objgen(16, 0)>,\n",
       "    \"/Rect\": [ Decimal('335.077'), Decimal('563.63'), Decimal('584.197'), Decimal('621.47') ],\n",
       "    \"/Subtype\": \"/Widget\",\n",
       "    \"/T\": \"Defendants name address and telephone\",\n",
       "    \"/Type\": \"/Annot\"\n",
       "  })},\n",
       " {'type': '/Tx',\n",
       "  'var_name': 'Third partys name address and telephone',\n",
       "  'all': pikepdf.Dictionary(Type=\"/Annot\")({\n",
       "    \"/DA\": \"/Helv 10 Tf 0 g\",\n",
       "    \"/F\": 4,\n",
       "    \"/FT\": \"/Tx\",\n",
       "    \"/Ff\": 8392704,\n",
       "    \"/MK\": {\n",
       "  \n",
       "    },\n",
       "    \"/P\": <Pdf.pages.from_objgen(16, 0)>,\n",
       "    \"/Rect\": [ Decimal('49.3571'), Decimal('491.51'), Decimal('298.477'), Decimal('550.07') ],\n",
       "    \"/Subtype\": \"/Widget\",\n",
       "    \"/T\": \"Third partys name address and telephone\",\n",
       "    \"/Type\": \"/Annot\"\n",
       "  })},\n",
       " {'type': '/Tx',\n",
       "  'var_name': 'dated',\n",
       "  'all': pikepdf.Dictionary(Type=\"/Annot\")({\n",
       "    \"/AA\": {\n",
       "  \n",
       "    },\n",
       "    \"/DA\": \"/Helv 10 Tf 0 g\",\n",
       "    \"/F\": 4,\n",
       "    \"/FT\": \"/Tx\",\n",
       "    \"/Ff\": 8388608,\n",
       "    \"/MK\": {\n",
       "  \n",
       "    },\n",
       "    \"/P\": <Pdf.pages.from_objgen(16, 0)>,\n",
       "    \"/Rect\": [ Decimal('373.649'), Decimal('467.739'), Decimal('582.888'), Decimal('485.102') ],\n",
       "    \"/Subtype\": \"/Widget\",\n",
       "    \"/T\": \"dated\",\n",
       "    \"/Type\": \"/Annot\"\n",
       "  })},\n",
       " {'type': '/Tx',\n",
       "  'var_name': 'reasons',\n",
       "  'all': pikepdf.Dictionary(Type=\"/Annot\")({\n",
       "    \"/DA\": \"/Helv 10 Tf 0 g\",\n",
       "    \"/F\": 4,\n",
       "    \"/FT\": \"/Tx\",\n",
       "    \"/Ff\": 8392704,\n",
       "    \"/MK\": {\n",
       "  \n",
       "    },\n",
       "    \"/P\": <Pdf.pages.from_objgen(16, 0)>,\n",
       "    \"/Rect\": [ Decimal('40.4105'), Decimal('216.788'), Decimal('592.343'), Decimal('446.756') ],\n",
       "    \"/Subtype\": \"/Widget\",\n",
       "    \"/T\": \"reasons\",\n",
       "    \"/Type\": \"/Annot\"\n",
       "  })},\n",
       " {'type': '/Btn',\n",
       "  'var_name': 'Form Instructions',\n",
       "  'all': <pikepdf.Dictionary(Type=\"/Annot\")({\n",
       "    \"/A\": {\n",
       "      \"/S\": \"/URI\",\n",
       "      \"/URI\": \"https://www.courts.michigan.gov/4a7bae/siteassets/forms/scao-approved/instfoc78.pdf\"\n",
       "    },\n",
       "    \"/AP\": {\n",
       "      \"/N\": pikepdf.Stream(owner=<...>, data=<...>, {\n",
       "          \"/BBox\": [ Decimal('0.0'), Decimal('0.0'), Decimal('89.4436'), Decimal('11.4639') ],\n",
       "          \"/Filter\": \"/FlateDecode\",\n",
       "          \"/FormType\": 1,\n",
       "          \"/Length\": 150,\n",
       "          \"/Matrix\": [ Decimal('1.0'), Decimal('0.0'), Decimal('0.0'), Decimal('1.0'), Decimal('0.0'), Decimal('0.0') ],\n",
       "          \"/Resources\": {\n",
       "            \"/Font\": {\n",
       "              \"/HeBo\": {\n",
       "                \"/BaseFont\": \"/Helvetica-Bold\",\n",
       "                \"/Encoding\": {\n",
       "                  \"/Differences\": [ 24, \"/breve\", \"/caron\", \"/circumflex\", \"/dotaccent\", \"/hungarumlaut\", \"/ogonek\", \"/ring\", \"/tilde\", 39, \"/quotesingle\", 96, \"/grave\", 128, \"/bullet\", \"/dagger\", \"/daggerdbl\", \"/ellipsis\", \"/emdash\", \"/endash\", \"/florin\", \"/fraction\", \"/guilsinglleft\", \"/guilsinglright\", \"/minus\", \"/perthousand\", \"/quotedblbase\", \"/quotedblleft\", \"/quotedblright\", \"/quoteleft\", \"/quoteright\", \"/quotesinglbase\", \"/trademark\", \"/fi\", \"/fl\", \"/Lslash\", \"/OE\", \"/Scaron\", \"/Ydieresis\", \"/Zcaron\", \"/dotlessi\", \"/lslash\", \"/oe\", \"/scaron\", \"/zcaron\", 160, \"/Euro\", 164, \"/currency\", 166, \"/brokenbar\", 168, \"/dieresis\", \"/copyright\", \"/ordfeminine\", 172, \"/logicalnot\", \"/.notdef\", \"/registered\", \"/macron\", \"/degree\", \"/plusminus\", \"/twosuperior\", \"/threesuperior\", \"/acute\", \"/mu\", 183, \"/periodcentered\", \"/cedilla\", \"/onesuperior\", \"/ordmasculine\", 188, \"/onequarter\", \"/onehalf\", \"/threequarters\", 192, \"/Agrave\", \"/Aacute\", \"/Acircumflex\", \"/Atilde\", \"/Adieresis\", \"/Aring\", \"/AE\", \"/Ccedilla\", \"/Egrave\", \"/Eacute\", \"/Ecircumflex\", \"/Edieresis\", \"/Igrave\", \"/Iacute\", \"/Icircumflex\", \"/Idieresis\", \"/Eth\", \"/Ntilde\", \"/Ograve\", \"/Oacute\", \"/Ocircumflex\", \"/Otilde\", \"/Odieresis\", \"/multiply\", \"/Oslash\", \"/Ugrave\", \"/Uacute\", \"/Ucircumflex\", \"/Udieresis\", \"/Yacute\", \"/Thorn\", \"/germandbls\", \"/agrave\", \"/aacute\", \"/acircumflex\", \"/atilde\", \"/adieresis\", \"/aring\", \"/ae\", \"/ccedilla\", \"/egrave\", \"/eacute\", \"/ecircumflex\", \"/edieresis\", \"/igrave\", \"/iacute\", \"/icircumflex\", \"/idieresis\", \"/eth\", \"/ntilde\", \"/ograve\", \"/oacute\", \"/ocircumflex\", \"/otilde\", \"/odieresis\", \"/divide\", \"/oslash\", \"/ugrave\", \"/uacute\", \"/ucircumflex\", \"/udieresis\", \"/yacute\", \"/thorn\", \"/ydieresis\" ],\n",
       "                  \"/Type\": \"/Encoding\"\n",
       "                },\n",
       "                \"/Name\": \"/HeBo\",\n",
       "                \"/Subtype\": \"/Type1\",\n",
       "                \"/Type\": \"/Font\"\n",
       "              }\n",
       "            },\n",
       "            \"/ProcSet\": [ \"/PDF\", \"/Text\" ]\n",
       "          },\n",
       "          \"/Subtype\": \"/Form\",\n",
       "          \"/Type\": \"/XObject\"\n",
       "        })\n",
       "    },\n",
       "    \"/DA\": \"/HeBo 8 Tf 0 g\",\n",
       "    \"/F\": 4,\n",
       "    \"/FT\": \"/Btn\",\n",
       "    \"/Ff\": 65536,\n",
       "    \"/MK\": {\n",
       "      \"/BC\": [ Decimal('0.0'), Decimal('0.0'), Decimal('0.0') ],\n",
       "      \"/BG\": [ Decimal('0.199997'), Decimal('1.0'), Decimal('0.399994') ],\n",
       "      \"/CA\": \"Form Instructions\",\n",
       "      \"/IF\": {\n",
       "  \n",
       "      }\n",
       "    },\n",
       "    \"/P\": <Pdf.pages.from_objgen(16, 0)>,\n",
       "    \"/Rect\": [ Decimal('28.8458'), Decimal('5.24701'), Decimal('118.289'), Decimal('16.711') ],\n",
       "    \"/Subtype\": \"/Widget\",\n",
       "    \"/T\": \"Form Instructions\",\n",
       "    \"/Type\": \"/Annot\"\n",
       "  })>}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "get_existing_pdf_fields(\"ML_training/auto/095b9dc651ce47eb8b62e0790974970f.pdf\")\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c00a71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_character_count(\n",
    "    field: pikepdf.Object, char_width: float = 6, row_height: float = 16\n",
    ") -> int:\n",
    "    if not hasattr(field[\"all\"], \"Rect\"):\n",
    "        return 1\n",
    "    # https://pikepdf.readthedocs.io/en/latest/api/main.html#pikepdf.Rectangle\n",
    "    # Rectangle with llx,lly,urx,ury\n",
    "    height = field[\"all\"].Rect[3] - field[\"all\"].Rect[1]  # type: ignore\n",
    "    width = field[\"all\"].Rect[2] - field[\"all\"].Rect[0]  # type: ignore\n",
    "    # height = field[\"all\"].Rect.height\n",
    "    # width = field[\"all\"].Rect.width\n",
    "    num_rows = int(height / row_height) if height > row_height else 1  # type: ignore\n",
    "    num_cols = int(width / char_width)  # type: ignore\n",
    "    max_chars = num_rows * num_cols\n",
    "    return max_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7bea88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputType(Enum):\n",
    "    \"\"\"\n",
    "    Input type maps onto the type of input the PDF author chose for the field. We only\n",
    "    handle text, checkbox, and signature fields.\n",
    "    \"\"\"\n",
    "\n",
    "    TEXT = \"text\"\n",
    "    CHECKBOX = \"checkbox\"\n",
    "    SIGNATURE = \"signature\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93af383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FieldInfo(TypedDict):\n",
    "    var_name: str\n",
    "    max_length: int\n",
    "    type: Union[InputType, str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57631a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def field_types_and_sizes(\n",
    "    fields: Iterable,\n",
    ") -> List[FieldInfo]:\n",
    "    \"\"\"\n",
    "    Transform the fields provided by get_existing_pdf_fields into a summary format.\n",
    "    Result will look like:\n",
    "    [\n",
    "        {\n",
    "            \"var_name\": var_name,\n",
    "            \"type\": \"text | checkbox | signature\",\n",
    "            \"max_length\": n\n",
    "        }\n",
    "    ]\n",
    "    \"\"\"\n",
    "    processed_fields: List[FieldInfo] = []\n",
    "    for field in fields:\n",
    "        item: FieldInfo = {\n",
    "            \"var_name\": field[\"var_name\"],\n",
    "            \"max_length\": get_character_count(\n",
    "                field,\n",
    "            ),\n",
    "            \"type\": \"\",\n",
    "        }\n",
    "        if field[\"type\"] == \"/Tx\":\n",
    "            item[\"type\"] = InputType.TEXT\n",
    "        elif field[\"type\"] == \"/Btn\":\n",
    "            item[\"type\"] = InputType.CHECKBOX\n",
    "        elif field[\"type\"] == \"/Sig\":\n",
    "            item[\"type\"] = InputType.SIGNATURE\n",
    "        else:\n",
    "            item[\"type\"] = str(field[\"type\"])\n",
    "        processed_fields.append(item)\n",
    "    return processed_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c5d0ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerType(Enum):\n",
    "    \"\"\"\n",
    "    Answer type describes the effort the user answering the form will require.\n",
    "    \"Slot-in\" answers are a matter of almost instantaneous recall, e.g., name, address, etc.\n",
    "    \"Gathered\" answers require looking around one's desk, for e.g., a health insurance number.\n",
    "    \"Third party\" answers require picking up the phone to call someone else who is the keeper\n",
    "    of the information.\n",
    "    \"Created\" answers don't exist before the user is presented with the question. They may include\n",
    "    a choice, creating a narrative, or even applying legal reasoning. \"Affidavits\" are a special\n",
    "    form of created answers.\n",
    "    See Jarret and Gaffney, Forms That Work (2008)\n",
    "    \"\"\"\n",
    "\n",
    "    SLOT_IN = \"slot in\"\n",
    "    GATHERED = \"gathered\"\n",
    "    THIRD_PARTY = \"third party\"\n",
    "    CREATED = \"created\"\n",
    "    AFFIDAVIT = \"affidavit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5b7feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_field(field: FieldInfo, new_name: str) -> AnswerType:\n",
    "    \"\"\"\n",
    "    Apply heuristics to the field's original and \"normalized\" name to classify\n",
    "    it as either a \"slot-in\", \"gathered\", \"third party\" or \"created\" field type.\n",
    "    \"\"\"\n",
    "    SLOT_IN_FIELDS = {\n",
    "        \"users1_name\",\n",
    "        \"users1_name\",\n",
    "        \"users1_birthdate\",\n",
    "        \"users1_address_line_one\",\n",
    "        \"users1_address_line_two\",\n",
    "        \"users1_address_city\",\n",
    "        \"users1_address_state\",\n",
    "        \"users1_address_zip\",\n",
    "        \"users1_phone_number\",\n",
    "        \"users1_email\",\n",
    "        \"plaintiff1_name\",\n",
    "        \"defendant1_name\",\n",
    "        \"petitioners1_name\",\n",
    "        \"respondents1_name\",\n",
    "        \"users1_signature\",\n",
    "        \"signature_date\",\n",
    "    }\n",
    "    SLOT_IN_KEYWORDS = {\n",
    "        \"name\",\n",
    "        \"birth date\",\n",
    "        \"birthdate\",\n",
    "        \"phone\",\n",
    "    }\n",
    "    GATHERED_KEYWORDS = {\n",
    "        \"number\",\n",
    "        \"value\",\n",
    "        \"amount\",\n",
    "        \"id number\",\n",
    "        \"social security\",\n",
    "        \"benefit id\",\n",
    "        \"docket\",\n",
    "        \"case\",\n",
    "        \"employer\",\n",
    "        \"date\",\n",
    "    }\n",
    "    CREATED_KEYWORDS = {\n",
    "        \"choose\",\n",
    "        \"choice\",\n",
    "        \"why\",\n",
    "        \"fact\",\n",
    "    }\n",
    "    AFFIDAVIT_KEYWORDS = {\n",
    "        \"affidavit\",\n",
    "    }\n",
    "    var_name = field[\"var_name\"].lower()\n",
    "    if (\n",
    "        var_name in SLOT_IN_FIELDS\n",
    "        or new_name in SLOT_IN_FIELDS\n",
    "        or any(keyword in var_name for keyword in SLOT_IN_KEYWORDS)\n",
    "    ):\n",
    "        return AnswerType.SLOT_IN\n",
    "    elif any(keyword in var_name for keyword in GATHERED_KEYWORDS):\n",
    "        return AnswerType.GATHERED\n",
    "    elif set(var_name.split()).intersection(CREATED_KEYWORDS):\n",
    "        return AnswerType.CREATED\n",
    "    elif field[\"type\"] == InputType.TEXT:\n",
    "        if field[\"max_length\"] <= 100:\n",
    "            return AnswerType.SLOT_IN\n",
    "        else:\n",
    "            return AnswerType.CREATED\n",
    "    return AnswerType.GATHERED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1663443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_answer_field(\n",
    "    field: FieldInfo,\n",
    "    new_name: str,\n",
    "    cpm: int = 40,\n",
    "    cpm_std_dev: int = 17,\n",
    ") -> Callable[[int], np.ndarray]:\n",
    "    \"\"\"\n",
    "    Apply a heuristic for the time it takes to answer the given field, in minutes.\n",
    "    It is hand-written for now.\n",
    "    It will factor in the input type, the answer type (slot in, gathered, third party or created), and the\n",
    "    amount of input text allowed in the field.\n",
    "    The return value is a function that can return N samples of how long it will take to answer the field\n",
    "    \"\"\"\n",
    "    # Average CPM is about 40: https://en.wikipedia.org/wiki/Words_per_minute#Handwriting\n",
    "    # Standard deviation is about 17 characters/minute\n",
    "    # Add mean amount of time for gathering or creating the answer itself (if any) + standard deviation\n",
    "    TIME_TO_MAKE_ANSWER = {\n",
    "        AnswerType.SLOT_IN: (0.25, 0.1),\n",
    "        AnswerType.GATHERED: (3, 2),\n",
    "        AnswerType.THIRD_PARTY: (5, 2),\n",
    "        AnswerType.CREATED: (5, 4),\n",
    "        AnswerType.AFFIDAVIT: (5, 4),\n",
    "    }\n",
    "    kind = classify_field(field, new_name)\n",
    "    if field[\"type\"] == InputType.SIGNATURE or \"signature\" in field[\"var_name\"]:\n",
    "        return lambda number_samples: np.random.normal(\n",
    "            loc=0.5, scale=0.1, size=number_samples\n",
    "        )\n",
    "    if field[\"type\"] == InputType.CHECKBOX:\n",
    "        return lambda number_samples: np.random.normal(\n",
    "            loc=TIME_TO_MAKE_ANSWER[kind][0],\n",
    "            scale=TIME_TO_MAKE_ANSWER[kind][1],\n",
    "            size=number_samples,\n",
    "        )\n",
    "    else:\n",
    "        # We chunk answers into three different lengths rather than directly using the character count,\n",
    "        # as forms can give very different spaces for the same data without regard to the room the\n",
    "        # user actually needs. But small, medium, and full page is still helpful information.\n",
    "        ONE_WORD = 4.7  # average word length: https://www.researchgate.net/figure/Average-word-length-in-the-English-language-Different-colours-indicate-the-results-for_fig1_230764201\n",
    "        ONE_LINE = 115  # Standard line is ~ 115 characters wide at 12 point font\n",
    "        SHORT_ANSWER = (\n",
    "            ONE_LINE * 2\n",
    "        )  # Anything over 1 line but less than 3 probably needs about the same time to answer\n",
    "        MEDIUM_ANSWER = ONE_LINE * 5\n",
    "        LONG_ANSWER = (\n",
    "            ONE_LINE * 10\n",
    "        )  # Anything over 10 lines probably needs a full page but form author skimped on space\n",
    "        if field[\"max_length\"] <= ONE_LINE or (\n",
    "            field[\"max_length\"] <= ONE_LINE * 2 and kind == AnswerType.SLOT_IN\n",
    "        ):\n",
    "            time_to_write_answer = ONE_WORD * 2 / cpm\n",
    "            time_to_write_std_dev = ONE_WORD * 2 / cpm_std_dev\n",
    "        elif field[\"max_length\"] <= SHORT_ANSWER:\n",
    "            time_to_write_answer = SHORT_ANSWER / cpm\n",
    "            time_to_write_std_dev = SHORT_ANSWER / cpm_std_dev\n",
    "        elif field[\"max_length\"] <= MEDIUM_ANSWER:\n",
    "            time_to_write_answer = MEDIUM_ANSWER / cpm\n",
    "            time_to_write_std_dev = MEDIUM_ANSWER / cpm_std_dev\n",
    "        else:\n",
    "            time_to_write_answer = LONG_ANSWER / cpm\n",
    "            time_to_write_std_dev = LONG_ANSWER / cpm_std_dev\n",
    "        return lambda number_samples: np.random.normal(\n",
    "            loc=time_to_write_answer, scale=time_to_write_std_dev, size=number_samples\n",
    "        ) + np.random.normal(\n",
    "            loc=TIME_TO_MAKE_ANSWER[kind][0],\n",
    "            scale=TIME_TO_MAKE_ANSWER[kind][1],\n",
    "            size=number_samples,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "400acf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_answer_form(processed_fields, normalized_fields) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Provide an estimate of how long it would take an average user to respond to the questions\n",
    "    on the provided form.\n",
    "    We use signals such as the field type, name, and space provided for the response to come up with a\n",
    "    rough estimate, based on whether the field is:\n",
    "    1. fill in the blank\n",
    "    2. gathered - e.g., an id number, case number, etc.\n",
    "    3. third party: need to actually ask someone the information - e.g., income of not the user, anything else?\n",
    "    4. created:\n",
    "        a. short created (3 lines or so?)\n",
    "        b. long created (anything over 3 lines)\n",
    "    \"\"\"\n",
    "    field_answer_time_simulators: List[Callable[[int], np.ndarray]] = []\n",
    "    for index, field in enumerate(processed_fields):\n",
    "        field_answer_time_simulators.append(\n",
    "            time_to_answer_field(field, normalized_fields[index])\n",
    "        )\n",
    "    # Run a monte carlo simulation to get times to answer and standard deviation\n",
    "    num_samples = 20000\n",
    "    np_array = np.zeros(num_samples)\n",
    "    for field_simulator in field_answer_time_simulators:\n",
    "        np_array += field_simulator(num_samples)\n",
    "    return sigfig.round(np_array.mean(), 2), sigfig.round(np_array.std(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "00650f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unlock_pdf_in_place(in_file: str):\n",
    "    \"\"\"\n",
    "    Try using pikePDF to unlock the PDF it it is locked. This won't work if it has a non-zero length password.\n",
    "    \"\"\"\n",
    "    if not isinstance(in_file, str):\n",
    "        return\n",
    "    pdf_file = pikepdf.open(in_file, allow_overwriting_input=True)\n",
    "    if pdf_file.is_encrypted:\n",
    "        pdf_file.save(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "caab3182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_text(text: str, fields_to_sentences: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Apply cleanup routines to text to provide more accurate readability statistics.\n",
    "    \"\"\"\n",
    "    # Replace \\n with .\n",
    "    text = re.sub(r\"(\\n|\\r)+\", \". \", text)\n",
    "    # Replace non-punctuation characters with \" \"\n",
    "    text = re.sub(r\"[^\\w.,;!?@'\\\"“”‘’'″‶ ]\", \" \", text)\n",
    "    # _ is considered a word character, remove it\n",
    "    text = re.sub(r\"_+\", \" \", text)\n",
    "    if fields_to_sentences:\n",
    "        # Turn : into . (so fields are treated as one sentence)\n",
    "        text = re.sub(r\":\", \".\", text)\n",
    "    # Condense repeated \" \"\n",
    "    text = re.sub(r\" +\", \" \", text)\n",
    "    # Remove any sentences that are just composed of a space\n",
    "    text = re.sub(r\"\\. +\\.\", \". \", text)\n",
    "    # Remove any repeated .\n",
    "    text = re.sub(r\"\\.+\", \".\", text)\n",
    "    # Remove space before final period\n",
    "    text = re.sub(r\" \\.\", \".\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f287c5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_caps_words(text: str) -> int:\n",
    "    results = re.findall(r\"([A-Z][A-Z]+)\", text)\n",
    "    if results:\n",
    "        return len(results)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2283b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n\\n \\n\\n \\n\\n \\n \\n \\n \\n \\nCheck your email. You will receive information and \\ndocuments at this email address.  \\n \\n\\nI am   [  ]  Petitioner \\n\\n[  ]  Petitioner’s Attorney \\n\\n(Utah Bar #:__________) \\n\\n[  ]  Respondent                     [  ]  Interested Person \\n[  ]  Respondent’s Attorney    [  ]  Interested Person's Attorney \\n\\nIn the District Court of Utah \\n\\n__________ Judicial District ________________ County \\n\\nCourt Address ______________________________________________________ \\n\\nIn the Matter of Protection for \\n\\nRequest for Order to Examine \\nRespondent \\n\\n___________________________________, \\nRespondent \\n\\n_______________________________ \\nCase Number \\n\\n_______________________________ \\nJudge \\n\\n1. \\n\\nI request that the court order the respondent be examined by \\n___________________________________________________________ (name)  \\n\\nwho is a physician licensed in the state of _________________________, and \\nwho will examine the respondent, evaluate the respondent’s functional \\nlimitations, and submit a written report to the court. \\n\\n2. \\n\\nI make this request because: \\n\\n \\nName \\n \\nAddress \\n \\nCity, State, Zip \\n \\nPhone \\n\\n \\nEmail  \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nRequest for Order to Examine Respondent \\n\\nApproved Board of District Court Judges September 12, 2012 \\nRevised December 19, 2019 \\n\\nPage 1 of 3 \\n\\n\\x0cI declare under criminal penalty under the law of Utah that everything stated in this document is true. \\n\\nSigned at ______________________________________________________ (city, and state or country). \\n\\n \\nDate \\n\\nSignature ► \\n\\nPrinted Name \\n\\n \\n\\n \\n\\nRequest for Order to Examine Respondent \\n\\nApproved Board of District Court Judges September 12, 2012 \\nRevised December 19, 2019 \\n\\nPage 2 of 3 \\n\\n \\n\\n\\x0c \\n\\n \\n\\n \\n\\n \\nDate \\n\\n \\n\\nCertificate of Service \\n\\nI certify that I filed with the court and am serving a copy of this Request for Order to Examine Respondent \\non the following people. \\n\\nPerson’s Name \\n\\nService Method \\n\\nService Address \\n\\nService \\nDate \\n\\n(Petitioner or Attorney) \\n\\n(Respondent or \\nAttorney) \\n\\n \\n\\n \\n\\n \\n\\n[  ]  Mail \\n[  ]  Hand Delivery \\n[  ]  E-filed \\n[  ]  Email \\n[  ]  Left at business (With person in charge \\n\\nor in receptacle for deliveries.) \\n\\n[  ]  Left at home (With person of suitable \\n\\nage and discretion residing there.) \\n\\n[  ]  Mail \\n[  ]  Hand Delivery \\n[  ]  E-filed \\n[  ]  Email \\n[  ]  Left at business (With person in charge \\n\\nor in receptacle for deliveries.) \\n\\n[  ]  Left at home (With person of suitable \\n\\nage and discretion residing there.) \\n\\n[  ]  Mail \\n[  ]  Hand Delivery \\n[  ]  E-filed \\n[  ]  Email  \\n[  ]  Left at business (With person in charge \\n\\nor in receptacle for deliveries.) \\n\\n[  ]  Left at home (With person of suitable \\n\\nage and discretion residing there.) \\n\\nSignature ► \\n\\nPrinted Name \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nRequest for Order to Examine Respondent \\n\\nApproved Board of District Court Judges September 12, 2012 \\nRevised December 19, 2019 \\n\\nPage 3 of 3 \\n\\n\\x0c\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "extract_text(\"ML_training/auto/3902bb0b832b4fa4b20e7635201017aa.pdf\")\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a09538a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approved, SCAO. STATE OF MICHIGAN. JUDICIAL CIRCUIT. COUNTY. Original Court. 1st copy Moving party. 2nd copy Objecting party. 3rd copy Friend of the court. 4th copy Proof of service. 5th copy Proof of service. A. CASE NO. OBJECTION TO PROPOSED ORDER. Court address. Court telephone no. Plaintiff's name, address, and telephone no. moving party. Defendant's name, address, and telephone no. moving party. v. Third party's name, address, and telephone no. moving party. I received a notice to enter a proposed order without a hearing dated. I object to the entry of the proposed order and request a hearing by the court. My objection is based on the following reason s. C. Moving party's signature. Name type or print. CERTIFICATE OF MAILING. Signature of objecting party. I certify that on this date I served a copy of this objection on the parties or their attorneys by first class mail addressed to their. last known addresses as defined in MCR 3.203. FOC 78 3 11 OBJECTION TO PROPOSED ORDER. MCR 2.602 B. B. D. E. Date. F. Date. \n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'8th and 9th grade'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "original_text = extract_text(\"ML_training/auto/095b9dc651ce47eb8b62e0790974970f.pdf\")\n",
    "text = cleanup_text(original_text)\n",
    "# text = re.sub(\"_\",\" \",text)\n",
    "# text = re.sub(\"\\s\",\". \",text)\n",
    "# text = re.sub(\" +\",\" \",text)\n",
    "print(text)\n",
    "print(text != \"\")\n",
    "textstat.text_standard(text)\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c05c392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TextComplete(prompt, max_tokens=500):\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=\"text-davinci-003\",\n",
    "            prompt=prompt,\n",
    "            temperature=0,\n",
    "            max_tokens=max_tokens,\n",
    "            top_p=1.0,\n",
    "            frequency_penalty=0.0,\n",
    "            presence_penalty=0.0,\n",
    "        )\n",
    "        return str(response[\"choices\"][0][\"text\"].strip())\n",
    "    except:\n",
    "        return \"Error\"\n",
    "\n",
    "\n",
    "def plain_lang(text):\n",
    "    tokens = len(tokenizer(text)[\"input_ids\"])\n",
    "    prompt = text + \"\\nRewrite the above at a sixth grade reading level.\"\n",
    "    output = TextComplete(prompt, max_tokens=tokens)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1f5992c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I got a notice to make a decision without a hearing. I don't agree and I want a hearing. Here's why: ___________________________________________________.\\n\\nI sent a copy of this to the people involved or their lawyers by mail. \\n\\nSignature of Objecting Party ___________________________\\nDate ___________________________\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "original_text = extract_text(\"ML_training/auto/095b9dc651ce47eb8b62e0790974970f.pdf\")\n",
    "text = cleanup_text(original_text)\n",
    "plain_lang(text)\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53c95e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_form_name(text):\n",
    "    tokens = 20\n",
    "    prompt = text + \"\\nThe text above is from a court form. Write the form's name.\"\n",
    "    output = TextComplete(prompt, max_tokens=tokens)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ac82cecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Objection to Proposed Order'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "original_text = extract_text(\"ML_training/auto/095b9dc651ce47eb8b62e0790974970f.pdf\")\n",
    "text = cleanup_text(original_text)\n",
    "guess_form_name(text)\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3d2ac7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_form(text):\n",
    "    tokens = 250\n",
    "    prompt = (\n",
    "        text\n",
    "        + \"\\nThe text above is from a court form. Write a brief description of its purpose at a sixth grade reading level.\"\n",
    "    )\n",
    "    output = TextComplete(prompt, max_tokens=tokens)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b28bc8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This form is used to object to a proposed court order. It allows someone to explain why they disagree with the proposed order and request a hearing by the court.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "original_text = extract_text(\"ML_training/auto/095b9dc651ce47eb8b62e0790974970f.pdf\")\n",
    "text = cleanup_text(original_text)\n",
    "describe_form(text)\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b66b6c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_form(\n",
    "    in_file: str,\n",
    "    title: Optional[str] = None,\n",
    "    jur: Optional[str] = None,\n",
    "    cat: Optional[str] = None,\n",
    "    normalize: bool = True,\n",
    "    use_spot: bool = False,\n",
    "    rewrite: bool = False,\n",
    "    debug: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Read in a pdf, pull out basic stats, attempt to normalize its form fields, and re-write the in_file with the new fields (if `rewrite=1`).\n",
    "    \"\"\"\n",
    "    unlock_pdf_in_place(in_file)\n",
    "    f = pikepdf.open(in_file)\n",
    "    npages = len(f.pages)\n",
    "\n",
    "    try:\n",
    "        with time_limit(15):\n",
    "            ff = get_existing_pdf_fields(f)\n",
    "    except TimeoutException as e:\n",
    "        print(\"Timed out!\")\n",
    "        ff = None\n",
    "    except AttributeError:\n",
    "        ff = None\n",
    "    if ff:\n",
    "        fields = [field[\"var_name\"] for field in ff]\n",
    "    else:\n",
    "        fields = []\n",
    "    f_per_page = len(fields) / npages\n",
    "    original_text = extract_text(in_file)\n",
    "    text = cleanup_text(original_text)\n",
    "    if title is None:\n",
    "        title = guess_form_name(text)\n",
    "        if title == \"Error\":\n",
    "            matches = re.search(\"(.*)\\n\", text)\n",
    "            if matches:\n",
    "                title = re_case(matches.group(1).strip())\n",
    "            else:\n",
    "                title = \"(Untitled)\"\n",
    "    try:\n",
    "        if text != \"\":\n",
    "            readability = textstat.text_standard(text, float_output=True)\n",
    "        else:\n",
    "            readability = -1\n",
    "    except:\n",
    "        readability = -1\n",
    "    if use_spot:\n",
    "        nmsi = spot(title + \". \" + text)\n",
    "    else:\n",
    "        nmsi = []\n",
    "    if normalize:\n",
    "        i = 0\n",
    "        length = len(fields)\n",
    "        last = \"null\"\n",
    "        new_fields = []\n",
    "        new_fields_conf = []\n",
    "        for field in fields:\n",
    "            # print(jur,cat,i,i/length,last,field)\n",
    "            this_field, this_conf = normalize_name(\n",
    "                jur or \"\", cat or \"\", i, i / length, last, field\n",
    "            )\n",
    "            new_fields.append(this_field)\n",
    "            new_fields_conf.append(this_conf)\n",
    "            last = field\n",
    "        new_fields = [\n",
    "            v + \"__\" + str(new_fields[:i].count(v) + 1)\n",
    "            if new_fields.count(v) > 1\n",
    "            else v\n",
    "            for i, v in enumerate(new_fields)\n",
    "        ]\n",
    "    else:\n",
    "        new_fields = fields\n",
    "        new_fields_conf = []\n",
    "    sentences = sent_tokenize(text)\n",
    "    # Sepehri, A., Markowitz, D. M., & Mir, M. (2022, February 3). PassivePy: A Tool to Automatically Identify Passive Voice in Big Text Data. Retrieved from psyarxiv.com/bwp3t\n",
    "    passive_text_df = passivepy.match_corpus_level(pd.DataFrame(sentences), 0)\n",
    "    passive_sentences = len(passive_text_df[passive_text_df[\"binary\"] > 0])\n",
    "    citations = eyecite.get_citations(\n",
    "        eyecite.clean_text(original_text, [\"all_whitespace\", \"underscores\"])\n",
    "    )\n",
    "    stats = {\n",
    "        \"title\": title,\n",
    "        \"category\": cat,\n",
    "        \"pages\": npages,\n",
    "        \"reading grade level\": readability,\n",
    "        \"time to answer\": time_to_answer_form(field_types_and_sizes(ff), new_fields)\n",
    "        if ff\n",
    "        else -1,\n",
    "        \"list\": nmsi,\n",
    "        \"avg fields per page\": f_per_page,\n",
    "        \"fields\": new_fields,\n",
    "        \"fields_conf\": new_fields_conf,\n",
    "        \"fields_old\": fields,\n",
    "        \"text\": text,\n",
    "        \"original_text\": original_text,\n",
    "        \"number of sentences\": len(sentences),\n",
    "        \"number of passive voice sentences\": passive_sentences,\n",
    "        \"number of all caps words\": all_caps_words(text),\n",
    "        \"citations\": [cite.matched_text() for cite in citations],\n",
    "    }\n",
    "    if debug and ff:\n",
    "        debug_fields = []\n",
    "        for index, field in enumerate(field_types_and_sizes(ff)):\n",
    "            debug_fields.append(\n",
    "                {\n",
    "                    \"name\": field[\"var_name\"],\n",
    "                    \"input type\": str(field[\"type\"]),\n",
    "                    \"max length\": field[\"max_length\"],\n",
    "                    \"inferred answer type\": str(\n",
    "                        classify_field(field, new_fields[index])\n",
    "                    ),\n",
    "                    \"time to answer\": time_to_answer_field(field, new_fields[index])(1),\n",
    "                }\n",
    "            )\n",
    "        stats[\"debug fields\"] = debug_fields\n",
    "    if rewrite:\n",
    "        try:\n",
    "            my_pdf = pikepdf.Pdf.open(in_file, allow_overwriting_input=True)\n",
    "            fields_too = (\n",
    "                my_pdf.Root.AcroForm.Fields\n",
    "            )  # [0][\"/Kids\"][0][\"/Kids\"][0][\"/Kids\"][0][\"/Kids\"]\n",
    "            # print(repr(fields_too))\n",
    "            for k, field in enumerate(new_fields):\n",
    "                # print(k,field)\n",
    "                fields_too[k].T = re.sub(\"^\\*\", \"\", field)\n",
    "            my_pdf.save(in_file)\n",
    "        except:\n",
    "            stats[\"error\"] = \"could not change form fields\"\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "782e2e2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting Sentences...\n",
      "Starting to find passives...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'title': 'Objection to Proposed Order',\n",
       " 'category': None,\n",
       " 'pages': 1,\n",
       " 'reading grade level': 6.0,\n",
       " 'time to answer': (63.0, 68.0),\n",
       " 'list': [],\n",
       " 'avg fields per page': 18.0,\n",
       " 'fields': ['moving_party__1',\n",
       "  'moving_party__2',\n",
       "  'moving_party__3',\n",
       "  '*signature_date__1',\n",
       "  'name_type_print',\n",
       "  '*signature_date__2',\n",
       "  'cas_e',\n",
       "  'judge',\n",
       "  'circuit',\n",
       "  'county',\n",
       "  '*users1_address_line_one',\n",
       "  'telno',\n",
       "  'name_address_telephone__1',\n",
       "  'name_address_telephone__2',\n",
       "  'third_name_address_telephone',\n",
       "  'dated',\n",
       "  'reasons',\n",
       "  'form_instructions'],\n",
       " 'fields_conf': [0.53,\n",
       "  0.56,\n",
       "  0.55,\n",
       "  1.0,\n",
       "  0.62,\n",
       "  1.0,\n",
       "  0.64,\n",
       "  0.68,\n",
       "  0.58,\n",
       "  0.64,\n",
       "  1.0,\n",
       "  0.97,\n",
       "  0.52,\n",
       "  0.55,\n",
       "  0.48,\n",
       "  0.55,\n",
       "  0.53,\n",
       "  0.61],\n",
       " 'fields_old': ['moving party',\n",
       "  'moving party_2',\n",
       "  'moving party_3',\n",
       "  'Date',\n",
       "  'Name type or print',\n",
       "  'Date_2',\n",
       "  'CASE NO',\n",
       "  'judge',\n",
       "  'circuit',\n",
       "  'county',\n",
       "  'address',\n",
       "  'telno',\n",
       "  'Plaintiffs name address and telephone',\n",
       "  'Defendants name address and telephone',\n",
       "  'Third partys name address and telephone',\n",
       "  'dated',\n",
       "  'reasons',\n",
       "  'Form Instructions'],\n",
       " 'text': \"Approved, SCAO. STATE OF MICHIGAN. JUDICIAL CIRCUIT. COUNTY. Original Court. 1st copy Moving party. 2nd copy Objecting party. 3rd copy Friend of the court. 4th copy Proof of service. 5th copy Proof of service. A. CASE NO. OBJECTION TO PROPOSED ORDER. Court address. Court telephone no. Plaintiff's name, address, and telephone no. moving party. Defendant's name, address, and telephone no. moving party. v. Third party's name, address, and telephone no. moving party. I received a notice to enter a proposed order without a hearing dated. I object to the entry of the proposed order and request a hearing by the court. My objection is based on the following reason s. C. B. D. E. Date. Moving party's signature. Name type or print. CERTIFICATE OF MAILING. I certify that on this date I served a copy of this objection on the parties or their attorneys by first class mail addressed to their. last known addresses as defined in MCR 3.203. F. Date. Signature of objecting party. FOC 78 3 11 OBJECTION TO PROPOSED ORDER. MCR 2.602 B. \",\n",
       " 'original_text': \"Approved, SCAO\\n\\nSTATE OF MICHIGAN\\n\\nJUDICIAL CIRCUIT\\nCOUNTY\\n\\nOriginal - Court\\n1st copy - Moving party\\n2nd copy - Objecting party\\n\\n3rd copy - Friend of the court\\n4th copy - Proof of service\\n5th copy - Proof of service\\n\\nA\\n\\nCASE NO.\\n\\nOBJECTION TO PROPOSED ORDER\\n\\nCourt  address\\n\\nCourt  telephone  no.\\n\\nPlaintiff's name, address, and telephone no.\\n\\nmoving party\\n\\nDefendant's name, address, and telephone no.\\n\\nmoving party\\n\\nv\\n\\nThird party's name, address, and telephone no.\\n\\nmoving party\\n\\nI received a notice to enter a proposed order without a hearing dated\\nI object to the entry of the proposed order and request a hearing by the court.  My objection is based on the following reason(s):\\n\\nC\\n\\nB\\n\\nD\\n\\nE\\n\\nDate\\n\\nMoving party's signature\\n\\nName (type or print)\\n\\nCERTIFICATE OF MAILING\\n\\nI certify that on this date I served a copy of this objection on the parties or their attorneys by first-class mail addressed to their\\nlast-known addresses as defined in MCR 3.203.\\n\\nF\\n\\nDate\\n\\nSignature of objecting party\\n\\nFOC 78   (3/11)   OBJECTION TO PROPOSED ORDER\\n\\nMCR 2.602(B)\\n\\n\\x0c\",\n",
       " 'number of sentences': 33,\n",
       " 'number of passive voice sentences': 0,\n",
       " 'number of all caps words': 23,\n",
       " 'citations': []}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "# parse_form(\"../data/processed/www.utcourts.gov/forms/898269a99ff1c65be10b1ae35bb34ba469fc14b7301b7ed7b126d195.pdf\",title=None,jur=\"UT\",cat=None,normalize=1)\n",
    "# parse_form(\"../data/processed/www.utcourts.gov/forms/2532cd2b6d3aaff8c47726a0abd168fb4e5cdb4977c065cd27bde8c7.pdf\",title=None,jur=\"UT\",cat=None,normalize=1)\n",
    "# parse_form(\"../data/processed/www.utcourts.gov/forms/6ec7576210513907e699b5adf3397639507c688801a60bc34c201984.pdf\",title=None,jur=\"UT\",cat=None,normalize=1)\n",
    "# parse_form(\"../data/processed/mjbportal.courts.maine.gov/forms/1519fe450d870a36a428a0b006c0665a.pdf\",title=None,jur=\"UT\",cat=None,normalize=1)\n",
    "# parse_form(\"../data/processed/www.courts.ca.gov/forms/3979f1c1c9f165ccac026b26cf20252c.pdf\",title=None,jur=\"UT\",cat=None,normalize=1)\n",
    "# parse_form(\"../data/processed/www.courts.michigan.gov/forms/52b2bf502a4bd8bc3a39a494a0ea5b0f491552e4d2da2ebe82beba3d.pdf\",title=None,jur=\"UT\",cat=None,normalize=1)\n",
    "\n",
    "# parse_form(\"../data/processed/www.utcourts.gov/forms/d94720b568d800e2510fbc04955687282a7e7419b78565d3e52c461c.pdf\",title=None,jur=\"MI\",cat=None,normalize=1,use_spot=1,rewrite=0)\n",
    "# parse_form(\"../data/processed/www.courts.michigan.gov/forms/147d1063a642a9f94693331190cc14599152610dc5cd489b5d17e46d.pdf\",title=None,jur=\"MI\",cat=None,normalize=1,use_spot=1,rewrite=0)\n",
    "# parse_form(\"../data/processed/www.courts.ca.gov/forms/e2c17a8503879d28d12932434d7c755b.pdf\",title=None,jur=\"CA\",cat=None,normalize=1,use_spot=1,rewrite=0)\n",
    "\n",
    "# parse_form(\"../data/processed/www.courts.ca.gov/forms/0d795fb4c4e35655370b5a6defa6b5cb.pdf\",title=None,jur=\"CA\",cat=None,normalize=1,use_spot=1,rewrite=0)\n",
    "\n",
    "parse_form(\n",
    "    \"ML_training/auto/095b9dc651ce47eb8b62e0790974970f.pdf\",\n",
    "    title=None,\n",
    "    jur=\"UT\",\n",
    "    cat=None,\n",
    "    normalize=1,\n",
    "    use_spot=1,\n",
    "    rewrite=0,\n",
    ")\n",
    "\n",
    "# my_pdf = pikepdf.Pdf.open(\"../data/processed/www.courts.ca.gov/forms/0d795fb4c4e35655370b5a6defa6b5cb.pdf\", allow_overwriting_input=True)\n",
    "# fields_too = my_pdf.Root.AcroForm.Fields #[0][\"/Kids\"][0][\"/Kids\"][0][\"/Kids\"][0][\"/Kids\"]\n",
    "# print(repr(fields_too))\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f775b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_complexity(text, fields, reading_lv):\n",
    "    # check for fields that require user to look up info, when found add to complexity\n",
    "    # maybe score these by minutes to recall/fill out\n",
    "    # so, figure out words per minute, mix in with readability and page number and field numbers\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "34be0b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current version: 0.0.10.2\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "# Save this notebook, then run this cell.\n",
    "\n",
    "import nbformat\n",
    "from nbconvert import PythonExporter\n",
    "from datetime import date\n",
    "\n",
    "today = date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "with open(\"functions.ipynb\") as fh:\n",
    "    nb = nbformat.reads(fh.read(), nbformat.NO_CONVERT)\n",
    "\n",
    "exporter = PythonExporter()\n",
    "source, meta = exporter.from_notebook_node(nb)\n",
    "\n",
    "with open(\"../formfyxer/lit_explorer.py\", \"w+\") as fh:\n",
    "    fh.writelines(source)\n",
    "\n",
    "local_load = \"\"\"included_fields = load(\n",
    "    os.path.join(os.path.dirname(__file__), \"data\", \"included_fields.joblib\")\n",
    ")\n",
    "jurisdictions = load(\n",
    "    os.path.join(os.path.dirname(__file__), \"data\", \"jurisdictions.joblib\")\n",
    ")\n",
    "groups = load(os.path.join(os.path.dirname(__file__), \"data\", \"groups.joblib\"))\n",
    "clf_field_names = load(\n",
    "    os.path.join(os.path.dirname(__file__), \"data\", \"clf_field_names.joblib\")\n",
    ")\n",
    "with open(\n",
    "    os.path.join(os.path.dirname(__file__), \"keys\", \"spot_token.txt\"), \"r\"\n",
    ") as in_file:\n",
    "    spot_token = in_file.read().rstrip()\n",
    "with open(\n",
    "    os.path.join(os.path.dirname(__file__), \"keys\", \"openai_org.txt\"), \"r\"\n",
    ") as in_file:\n",
    "    openai.organization = in_file.read().rstrip()\n",
    "with open(\n",
    "    os.path.join(os.path.dirname(__file__), \"keys\", \"openai_key.txt\"), \"r\"\n",
    ") as in_file:\n",
    "    openai.api_key = in_file.read().rstrip()\"\"\"\n",
    "\n",
    "with open(\"../formfyxer/lit_explorer.py\", \"r\") as file:\n",
    "    content = file.read()  # read everything in the file\n",
    "    content = re.sub(\"#!/usr/bin/env python\\n\", \"\", content, flags=re.M)\n",
    "    content = re.sub(\"# coding: utf-8\\n\", \"\", content, flags=re.M)\n",
    "    content = re.sub(\"# load local stuff\\n\", local_load, content, flags=re.M)\n",
    "    content = re.sub(\n",
    "        \"(?<=#{25}\\n#\\s{6}Start Test\\n#{25}\\n)(^(?!.*#{25}).*$\\n)*(?=#{25}\\n#\\s{7}End Test\\n#{25}\\n)\",\n",
    "        \"\",\n",
    "        content,\n",
    "        flags=re.M,\n",
    "    )\n",
    "    content = re.sub(\n",
    "        \"#{25}\\n#\\s{6}Start Test\\n#{25}\\n|#{25}\\n#\\s{7}End Test\\n#{25}\\n|#\\sIn\\[(\\d*|\\s*)\\]:\\n\",\n",
    "        \"\",\n",
    "        content,\n",
    "        flags=re.M,\n",
    "    )\n",
    "    content = re.sub(\"\\n\\n\\n\\n+\", \"\\n\\n\", content, flags=re.M)\n",
    "    content = re.sub(\"^\\n+\", \"\", content)\n",
    "\n",
    "with open(\"../formfyxer/lit_explorer.py\", \"w\") as file:\n",
    "    file.write(\"# Updated on \" + today + \"\\n\\n\" + content)\n",
    "\n",
    "with open(\"../setup.py\", \"r\") as file:\n",
    "    content = file.read()\n",
    "    version = re.findall(\"version='(\\d+\\.\\d+\\.\\d+\\.\\d+)'\", content)[0]\n",
    "\n",
    "print(\"Current version: %s\" % version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4e8ebf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter new version number or leave blank to keep.\n",
      "0.0.10.2\n"
     ]
    }
   ],
   "source": [
    "new_v = input(\"Enter new version number or leave blank to keep.\\n\")\n",
    "if len(re.findall(\"(\\d+\\.\\d+\\.\\d+\\.\\d+)\", new_v)) > 0:\n",
    "    with open(\"../setup.py\", \"w\") as file:\n",
    "        content = re.sub(\n",
    "            \"version='(\\d+\\.\\d+\\.\\d+\\.\\d+)'\", \"version='%s'\" % new_v, content\n",
    "        )\n",
    "        file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89d7687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
