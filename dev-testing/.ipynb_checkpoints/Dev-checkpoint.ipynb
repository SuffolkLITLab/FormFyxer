{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import PyPDF2\n",
    "import pikepdf\n",
    "import textstat\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "from numpy import unique\n",
    "from numpy import where\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "from joblib import load\n",
    "try:\n",
    "    from nltk.corpus import stopwords\n",
    "except:\n",
    "    print(\"Downloading stopwords\")\n",
    "    nltk.download('stopwords')\n",
    "    from nltk.corpus import stopwords\n",
    "import math\n",
    "import signal\n",
    "from contextlib import contextmanager\n",
    "import threading\n",
    "import _thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_lg') # this takes a while to loadimport os\n",
    "except OSError:\n",
    "    print(\"Downloading word2vec model en_core_web_lg\")\n",
    "    import subprocess\n",
    "    bashCommand = \"python -m spacy download en_core_web_lg\"\n",
    "    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    nlp = spacy.load('en_core_web_lg') # this takes a while to loadimport os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load local variables, models, and API key(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load local stuff\n",
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "included_fields = load('lib/data/included_fields.joblib')\n",
    "jurisdictions = load('lib/data/jurisdictions.joblib')\n",
    "groups = load('lib/data/groups.joblib')\n",
    "clf_field_names = load('lib/data/clf_field_names.joblib')\n",
    "with open('../data/keys/spot_token.txt', 'r') as file:\n",
    "    spot_token = file.read().rstrip()\n",
    "    \n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a timeout exception that can be triggered when something hangs too long. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeoutException(Exception): pass\n",
    "@contextmanager\n",
    "def time_limit(seconds):\n",
    "    timer = threading.Timer(seconds, lambda: _thread.interrupt_main())\n",
    "    timer.start()\n",
    "    try:\n",
    "        yield\n",
    "    except KeyboardInterrupt:\n",
    "        raise TimeoutException(\"Timed out.\")\n",
    "    finally:\n",
    "        # if the action ends in specified time, timer is canceled\n",
    "        timer.cancel()\n",
    "#    def signal_handler(signum, frame):\n",
    "#        raise TimeoutException(\"Timed out!\")\n",
    "#    signal.signal(signal.SIGALRM, signal_handler)\n",
    "#    signal.alarm(seconds)\n",
    "#    try:\n",
    "#        yield\n",
    "#    finally:\n",
    "#        signal.alarm(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timed out!\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "import time\n",
    "try:\n",
    "    with time_limit(1):\n",
    "        time.sleep(3)\n",
    "except TimeoutException as e:\n",
    "    print(\"Timed out!\")\n",
    "    \n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull ID values out of the LIST/NSMI results from Spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_get_id(values_to_unpack, tmpl=None):\n",
    "    # h/t to Quinten and Bryce for this code ;)\n",
    "    if not tmpl:\n",
    "        tmpl = set()\n",
    "    if isinstance(values_to_unpack, dict):\n",
    "        tmpl.add(values_to_unpack.get('id'))\n",
    "        if values_to_unpack.get('children'):\n",
    "            tmpl.update(recursive_get_id(values_to_unpack.get('children'), tmpl))\n",
    "        return tmpl\n",
    "    elif isinstance(values_to_unpack, list):\n",
    "        for item in values_to_unpack:\n",
    "            tmpl.update(recursive_get_id(item, tmpl))\n",
    "        return tmpl\n",
    "    else:\n",
    "        return set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HO-00-00-00-00', 'HO-06-00-00-00'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "spot_output = {  'build': 9,\n",
    "                 'query-id': '0dd2c6502bd64c76ae70b18d1c33029f',\n",
    "                 'text': 'My landlord is kicking me out of my home!',\n",
    "                 'save-text': 0,\n",
    "                 'cutoff-lower': 0.25,\n",
    "                 'cutoff-pred': 0.5,\n",
    "                 'cutoff-upper': 0.6,\n",
    "                 'labels': [{  \n",
    "                               'id': 'HO-00-00-00-00',\n",
    "                               'name': 'Housing',\n",
    "                               'lower': 0.6576830054321086,\n",
    "                               'pred': 0.6982554666277648,\n",
    "                               'upper': 0.7171144999635295,\n",
    "                               'children': [{\n",
    "                                             'id': 'HO-06-00-00-00',\n",
    "                                             'name': 'Renting or leasing a home',\n",
    "                                             'lower': 0.6705320866392293,\n",
    "                                             'pred': 0.8859675570562203,\n",
    "                                             'upper': 0.9113575931804385\n",
    "                                            }]\n",
    "                            }]\n",
    "               }\n",
    "recursive_get_id(spot_output[\"labels\"])\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the Spot API, but return only the IDs of issues found in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spot(text,lower=0.25,pred=0.5,upper=0.6):\n",
    "\n",
    "    headers = { \"Authorization\": \"Bearer \" + spot_token, \"Content-Type\":\"application/json\" }\n",
    "\n",
    "    body = {\n",
    "      \"text\": text,\n",
    "      \"save-text\": 0,\n",
    "      \"cutoff-lower\": lower,\n",
    "      \"cutoff-pred\": pred,\n",
    "      \"cutoff-upper\": upper\n",
    "    }\n",
    "\n",
    "    r = requests.post('https://spot.suffolklitlab.org/v0/entities-nested/', headers=headers, data=json.dumps(body))\n",
    "    output_ = r.json()\n",
    "\n",
    "    try:\n",
    "        return list(recursive_get_id(output_[\"labels\"]))\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "spot(\"My landlord is kicking me out of my home!\")\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to pull words out of snake_case, camelCase and the like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reCase(text):\n",
    "    output = re.sub(\"(\\w|\\d)(_|-)(\\w|\\d)\",\"\\\\1 \\\\3\",text.strip())\n",
    "    output = re.sub(\"([a-z])([A-Z]|\\d)\",\"\\\\1 \\\\2\",output)\n",
    "    output = re.sub(\"(\\d)([A-Z]|[a-z])\",\"\\\\1 \\\\2\",output)\n",
    "    output = re.sub(\"([A-Z]|[a-z])(\\d)\",\"\\\\1 \\\\2\",output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deal with snake case, camel Case and similarly formated text.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "reCase(\"Deal with snake_case, camelCase and similarly-formated text.\")\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes text from an auto-generated field name and uses regex to convert it into an Assembly Line standard field.\n",
    "See https://suffolklitlab.org/docassemble-AssemblyLine-documentation/docs/label_variables/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_norm_field(text):\n",
    "    \n",
    "    regex_list = [\n",
    "\n",
    "        # Personal info\n",
    "        ## Name & Bio\n",
    "        [\"^((My|Your|Full( legal)?) )?Name$\",\"users1_name\"],\n",
    "        [\"^(Typed or )?Printed Name\\s?\\d*$\",\"users1_name\"],\n",
    "        [\"^(DOB|Date of Birth|Birthday)$\",\"users1_birthdate\"],\n",
    "        ## Address\n",
    "        [\"^(Street )?Address$\",\"users1_address_line_one\"],\n",
    "        [\"^City State Zip$\",\"users1_address_line_two\"],\n",
    "        [\"^City$\",\"users1_address_city\"],\n",
    "        [\"^State$\",\"users1_address_state\"],\n",
    "        [\"^Zip( Code)?$\",\"users1_address_zip\"],\n",
    "        ## Contact\n",
    "        [\"^(Phone|Telephone)$\",\"users1_phone_number\"],\n",
    "        [\"^Email( Adress)$\",\"users1_email\"],\n",
    "\n",
    "        # Parties\n",
    "        [\"^plaintiff\\(?s?\\)?$\",\"plantiff1_name\"],\n",
    "        [\"^defendant\\(?s?\\)?$\",\"defendant1_name\"],\n",
    "        [\"^petitioner\\(?s?\\)?$\",\"petitioners1_name\"],\n",
    "        [\"^respondent\\(?s?\\)?$\",\"respondents1_name\"],\n",
    "\n",
    "        # Court info\n",
    "        [\"^(Court\\s)?Case\\s?(No|Number)?\\s?A?$\",\"docket_number\"],\n",
    "        [\"^File\\s?(No|Number)?\\s?A?$\",\"docket_number\"],\n",
    "\n",
    "        # Form info\n",
    "        [\"^(Signature|Sign( here)?)\\s?\\d*$\",\"users1_signature\"],\n",
    "        [\"^Date\\s?\\d*$\",\"signature_date\"],\n",
    "    ]\n",
    "\n",
    "    for regex in regex_list:\n",
    "        text = re.sub(regex[0],regex[1],text, flags=re.IGNORECASE)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'users1_name'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "regex_norm_field(\"Name\")\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranforms a string of text into a snake_case variable close in length to `max_length` name by summarizing the string and stiching the summary together in snake_case. h/t h/t https://towardsdatascience.com/nlp-building-a-summariser-68e0c19e3a93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_field(text,max_length=30):\n",
    "    orig_title = text.lower()\n",
    "    orig_title = re.sub(\"[^a-zA-Z]+\",\" \",orig_title)\n",
    "    orig_title_words = orig_title.split()\n",
    "\n",
    "    deduped_sentence = []\n",
    "    for word in orig_title_words:\n",
    "        if word not in deduped_sentence:\n",
    "            deduped_sentence.append(word)\n",
    "\n",
    "    filtered_sentence = [w for w in deduped_sentence if not w.lower() in stop_words]\n",
    "\n",
    "    filtered_title_words = filtered_sentence\n",
    "\n",
    "    characters = len(' '.join(filtered_title_words))\n",
    "\n",
    "    if characters > 0:\n",
    "\n",
    "        words = len(filtered_title_words)\n",
    "        av_word_len = math.ceil(len(' '.join(filtered_title_words))/len(filtered_title_words))\n",
    "        x_words = math.floor((max_length)/av_word_len)\n",
    "\n",
    "\n",
    "        sim_mat = np.zeros([len(filtered_title_words),len(filtered_title_words)])\n",
    "        # for each word compared to other\n",
    "        for i in range(len(filtered_title_words)):\n",
    "            for j in range(len(filtered_title_words)):\n",
    "                if i != j:\n",
    "                    sim_mat[i][j] = cosine_similarity(nlp(filtered_title_words[i]).vector.reshape(1,300), nlp(filtered_title_words[j]).vector.reshape(1,300))[0,0]\n",
    "\n",
    "        try:\n",
    "            nx_graph = nx.from_numpy_array(sim_mat)\n",
    "            scores = nx.pagerank(nx_graph)\n",
    "            sorted_scores = sorted(scores.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "            if x_words > len(scores):\n",
    "                x_words=len(scores)\n",
    "\n",
    "            i = 0\n",
    "            new_title = \"\"\n",
    "            for x in filtered_title_words:\n",
    "                if scores[i] >= sorted_scores[x_words-1][1]:\n",
    "                    if len(new_title)>0: new_title+=\"_\"\n",
    "                    new_title += x\n",
    "                i+=1\n",
    "\n",
    "            return new_title\n",
    "        except:\n",
    "            return '_'.join(filtered_title_words)\n",
    "    else:\n",
    "        if re.search(\"^(\\d+)$\", text):\n",
    "            return \"unknown\"\n",
    "        else:\n",
    "            return re.sub(\"\\s+\",\"_\",text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'name_field_fill'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "reformat_field(\"this is a name field where you fill out your name\")\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize a string of text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(text):\n",
    "    output = nlp(str(text)).vector\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.13013589e-01,  3.12421650e-01, -1.20467708e-01, -3.12428959e-02,\n",
       "        3.62497084e-02,  1.28887519e-01,  5.64192720e-02, -2.78512329e-01,\n",
       "       -3.36407930e-01,  1.55933702e+00, -1.72489524e-01, -1.16480077e-02,\n",
       "       -2.68756121e-01, -2.70458981e-02, -3.18187058e-01, -2.45410472e-01,\n",
       "        5.21429814e-02,  1.54589176e+00, -1.12968512e-01,  1.06057107e-01,\n",
       "        8.91231745e-02,  3.39188278e-02, -4.11080495e-02, -4.37215306e-02,\n",
       "       -7.70686269e-02, -4.02998850e-02, -2.89326757e-01, -3.38935503e-03,\n",
       "       -1.47982361e-02, -1.34107858e-01, -1.00483648e-01,  1.41670063e-01,\n",
       "       -1.06036467e-02, -1.25555053e-01,  2.97597766e-01,  3.82642411e-02,\n",
       "        7.61021525e-02,  1.06348701e-01, -1.63999036e-01, -2.03580678e-01,\n",
       "       -8.27748924e-02,  2.44145423e-01, -2.77349427e-02, -1.78780317e-01,\n",
       "        1.18556768e-01,  1.16618676e-02, -3.60679418e-01, -3.39524031e-01,\n",
       "       -6.04647063e-02,  3.09849262e-01, -4.76841219e-02,  1.36718765e-01,\n",
       "        1.21821702e-01, -9.25804079e-02,  8.70111734e-02, -1.52639061e-01,\n",
       "       -7.90559500e-02,  9.54141170e-02,  1.68904290e-01,  3.97630036e-02,\n",
       "       -2.11293235e-01,  1.45039514e-01,  3.15100588e-02,  2.40374088e-01,\n",
       "        7.17499405e-02, -1.18390419e-01, -1.81074649e-01, -3.58754098e-02,\n",
       "        2.25285348e-02,  2.77734697e-02,  3.02323312e-01, -9.28211138e-02,\n",
       "        7.65662342e-02,  1.88735843e-01, -1.68899714e-03,  2.14816511e-01,\n",
       "        8.44987035e-02, -6.52168840e-02,  5.20729385e-02,  7.60016739e-02,\n",
       "        9.39117000e-02,  1.09185288e-02, -3.11423540e-02, -5.33087254e-02,\n",
       "       -6.13311753e-02, -4.95994017e-02,  5.93046546e-01,  1.85197070e-01,\n",
       "        2.77876616e-01,  6.86455891e-02,  2.50347108e-02, -4.20601144e-02,\n",
       "       -8.79584923e-02, -7.20472410e-02,  1.62315980e-01, -1.38627421e-02,\n",
       "        1.91538319e-01,  1.21159710e-01, -1.06149234e-01,  9.70576610e-03,\n",
       "       -3.58194076e-02,  6.16732985e-02, -1.64352193e-01,  1.01822123e-01,\n",
       "       -2.37698719e-01, -8.40747774e-01,  5.41184768e-02,  2.35891771e-02,\n",
       "        9.67000872e-02, -8.21658745e-02,  7.28224739e-02,  1.89202391e-02,\n",
       "        4.26500067e-02, -3.47012818e-01,  6.10405281e-02,  2.06719086e-01,\n",
       "        1.27913013e-01, -1.03432693e-01,  1.77932382e-02,  1.33496165e-01,\n",
       "       -3.47520933e-02,  9.39188059e-03,  4.44273576e-02,  8.23991820e-02,\n",
       "        2.70191506e-02,  4.90782270e-03,  3.91958794e-03, -1.88633695e-01,\n",
       "       -4.46445867e-02,  4.89131846e-02, -1.09635480e-01, -6.73763920e-04,\n",
       "       -6.61776261e-03, -2.47771200e-02, -5.22734001e-02, -1.63720530e-02,\n",
       "       -6.74265251e-02, -1.09030060e-01,  1.85679402e-02, -2.34510377e-01,\n",
       "       -1.79144228e+00,  2.23494042e-02, -5.80148846e-02,  5.55704013e-02,\n",
       "       -1.16520695e-01,  2.05797702e-02, -7.28819296e-02, -3.87611636e-03,\n",
       "        2.59244412e-01, -1.23371825e-01, -8.16638917e-02, -2.48691179e-02,\n",
       "       -1.02678597e-01,  1.45087942e-01,  1.00950181e-01, -5.60914055e-02,\n",
       "       -1.03730531e-02, -9.74975824e-02,  1.15013108e-01,  1.27673715e-01,\n",
       "        1.10676512e-01,  1.40324058e-02, -4.92751062e-01,  1.73023537e-01,\n",
       "       -2.87811807e-03, -3.77760604e-02,  8.23729411e-02, -1.60091534e-01,\n",
       "        3.33402939e-02,  1.51509978e-02, -3.67459655e-02, -4.89723310e-02,\n",
       "        7.74993524e-02,  4.90004718e-02, -2.54121333e-01,  2.84605585e-02,\n",
       "        6.42405301e-02,  7.97412395e-02,  3.11562061e-01, -1.66010365e-01,\n",
       "       -5.73812351e-02,  1.46178296e-02,  8.05270206e-03, -1.81335919e-02,\n",
       "       -7.72526562e-02,  3.38562243e-02,  1.64881200e-02, -6.56182319e-02,\n",
       "        6.28871769e-02,  9.94776487e-02, -1.25716060e-01,  6.70209378e-02,\n",
       "       -1.79496646e-01,  4.09843512e-02, -9.67781842e-02,  1.44944191e-01,\n",
       "       -1.56434000e-01, -1.21532470e-01,  8.18147659e-02, -1.49101183e-01,\n",
       "       -2.74047069e-02, -6.11314848e-02,  1.78608179e-01, -9.15855095e-02,\n",
       "        2.79406458e-01,  1.27912417e-01, -4.35665883e-02, -1.05978232e-02,\n",
       "        1.81453362e-01,  1.07644172e-02, -8.09091777e-02,  1.60250574e-01,\n",
       "        4.79899859e-03, -3.13255899e-02,  2.76214033e-01,  2.60181010e-01,\n",
       "       -2.59297676e-02,  2.29535148e-01, -1.49327949e-01, -2.23262887e-02,\n",
       "        8.88084620e-02,  5.86275943e-02,  8.89510661e-02,  6.69021392e-03,\n",
       "        7.57751837e-02,  1.94170550e-02, -2.98427671e-01,  1.51288763e-01,\n",
       "       -1.29115418e-01,  1.92619577e-01,  7.42087066e-02,  2.51058280e-03,\n",
       "        2.58868188e-02,  1.03090875e-01, -1.14060774e-01, -2.13483363e-01,\n",
       "       -3.89549397e-02, -8.34967047e-02, -1.63730040e-01,  2.38725409e-01,\n",
       "        2.16264129e-01,  2.45557595e-02,  1.08124174e-01, -5.15342280e-02,\n",
       "        1.58610597e-01, -1.34693861e-01, -3.76047045e-02, -3.42159599e-01,\n",
       "       -1.18749730e-01,  1.06453717e-01,  3.35164189e-01, -2.83597976e-01,\n",
       "       -1.43357873e-01, -5.87592982e-02, -1.30963936e-01,  2.30296150e-01,\n",
       "        1.45184398e-01,  9.03599337e-03,  1.93905517e-01,  1.09368414e-01,\n",
       "        1.44885898e-01,  1.38844848e-01, -1.26822963e-01,  1.93229869e-01,\n",
       "        4.46362421e-02,  3.87822315e-02, -9.51401070e-02, -8.87758583e-02,\n",
       "       -4.60669361e-02,  3.68877321e-01,  2.39974946e-01, -3.79055925e-02,\n",
       "        9.47600007e-02, -2.42426455e-01, -2.48907149e-01,  7.64537752e-02,\n",
       "        7.63775334e-02,  1.27537757e-01, -9.76211056e-02,  1.27716690e-01,\n",
       "        1.07440069e-01,  1.70593366e-01, -1.14196517e-01, -1.49709731e-01,\n",
       "        1.88920572e-02, -2.33909085e-01,  7.79872984e-02,  4.88006091e-03,\n",
       "       -1.52774289e-01, -1.95967734e-01,  1.88715328e-02, -1.20045125e-01,\n",
       "       -8.56644586e-02, -2.28846353e-02,  9.67323482e-02,  4.18395996e-02,\n",
       "       -1.66458189e-01, -2.40994707e-01, -8.85597616e-02,  1.80236936e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "vectorize(\"how much wood would a wood chuck chuck, if a wood chuck could chuck wood?\")\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize a word vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(row):\n",
    "    try:\n",
    "        matrix = row.reshape(1,-1).astype(np.float64)\n",
    "        return normalize(matrix, axis=1, norm='l1')[0]\n",
    "    except Exception as e:\n",
    "        print(\"===================\")\n",
    "        print(\"Error: \",e)\n",
    "        print(\"===================\")\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.50101742e-03,  8.06820326e-03, -3.11104545e-03, -8.06839201e-04,\n",
       "        9.36138759e-04,  3.32848477e-03,  1.45701220e-03, -7.19250437e-03,\n",
       "       -8.68764235e-03,  4.02694501e-02, -4.45449456e-03, -3.00806598e-04,\n",
       "       -6.94055299e-03, -6.98452888e-04, -8.21709334e-03, -6.33765801e-03,\n",
       "        1.34657817e-03,  3.99222300e-02, -2.91738078e-03,  2.73889566e-03,\n",
       "        2.30158149e-03,  8.75944407e-04, -1.06160408e-03, -1.12909651e-03,\n",
       "       -1.99027611e-03, -1.04073346e-03, -7.47178401e-03, -8.75291623e-05,\n",
       "       -3.82160381e-04, -3.46329858e-03, -2.59496261e-03,  3.65859045e-03,\n",
       "       -2.73836264e-04, -3.24242475e-03,  7.68538053e-03,  9.88163512e-04,\n",
       "        1.96531718e-03,  2.74642598e-03, -4.23523004e-03, -5.25741506e-03,\n",
       "       -2.13763885e-03,  6.30498847e-03, -7.16247275e-04, -4.61695257e-03,\n",
       "        3.06169595e-03,  3.01164527e-04, -9.31444686e-03, -8.76811480e-03,\n",
       "       -1.56148443e-03,  8.00177206e-03, -1.23142935e-03,  3.53072454e-03,\n",
       "        3.14601197e-03, -2.39086359e-03,  2.24703964e-03, -3.94186182e-03,\n",
       "       -2.04159819e-03,  2.46404335e-03,  4.36190687e-03,  1.02686864e-03,\n",
       "       -5.45658975e-03,  3.74560559e-03,  8.13738610e-04,  6.20759478e-03,\n",
       "        1.85292250e-03, -3.05740003e-03, -4.67620306e-03, -9.26472602e-04,\n",
       "        5.81793220e-04,  7.17242223e-04,  7.80741645e-03, -2.39707976e-03,\n",
       "        1.97730196e-03,  4.87405128e-03, -4.36178872e-05,  5.54757736e-03,\n",
       "        2.18215580e-03, -1.68420811e-03,  1.34476933e-03,  1.96272235e-03,\n",
       "        2.42524385e-03,  2.81968005e-04, -8.04242735e-04, -1.37668318e-03,\n",
       "       -1.58386075e-03, -1.28089092e-03,  1.53152641e-02,  4.78266345e-03,\n",
       "        7.17608724e-03,  1.77275348e-03,  6.46514527e-04, -1.08619090e-03,\n",
       "       -2.27150390e-03, -1.86060020e-03,  4.19176557e-03, -3.58001506e-04,\n",
       "        4.94642446e-03,  3.12891622e-03, -2.74127480e-03,  2.50648743e-04,\n",
       "       -9.25026358e-04,  1.59269599e-03, -4.24435024e-03,  2.62952835e-03,\n",
       "       -6.13850410e-03, -2.17120802e-02,  1.39759479e-03,  6.09184016e-04,\n",
       "        2.49725318e-03, -2.12191113e-03,  1.88062038e-03,  4.88609975e-04,\n",
       "        1.10142470e-03, -8.96151067e-03,  1.57635487e-03,  5.33846358e-03,\n",
       "        3.30331842e-03, -2.67112087e-03,  4.59505487e-04,  3.44750179e-03,\n",
       "       -8.97463260e-04,  2.42542736e-04,  1.14732430e-03,  2.12793623e-03,\n",
       "        6.97762139e-04,  1.26743173e-04,  1.01222281e-04, -4.87141335e-03,\n",
       "       -1.15293419e-03,  1.26316955e-03, -2.83130614e-03, -1.73997681e-05,\n",
       "       -1.70901901e-04, -6.39862315e-04, -1.34994620e-03, -4.22803769e-04,\n",
       "       -1.74127148e-03, -2.81567135e-03,  4.79511954e-04, -6.05616605e-03,\n",
       "       -4.62635045e-02,  5.77167222e-04, -1.49821845e-03,  1.43509034e-03,\n",
       "       -3.00911494e-03,  5.31466911e-04, -1.88215581e-03, -1.00099640e-04,\n",
       "        6.69491571e-03, -3.18604347e-03, -2.10894756e-03, -6.42238136e-04,\n",
       "       -2.65164655e-03,  3.74685625e-03,  2.60701070e-03, -1.44854513e-03,\n",
       "       -2.67881247e-04, -2.51784828e-03,  2.97018190e-03,  3.29713862e-03,\n",
       "        2.85819052e-03,  3.62383024e-04, -1.27251608e-02,  4.46828530e-03,\n",
       "       -7.43266084e-05, -9.75556380e-04,  2.12725857e-03, -4.13431988e-03,\n",
       "        8.61003929e-04,  3.91270355e-04, -9.48954462e-04, -1.26469699e-03,\n",
       "        2.00139948e-03,  1.26542372e-03, -6.56261361e-03,  7.34986103e-04,\n",
       "        1.65899404e-03,  2.05929560e-03,  8.04600463e-03, -4.28717206e-03,\n",
       "       -1.48185463e-03,  3.77501432e-04,  2.07958818e-04, -4.68295027e-04,\n",
       "       -1.99502862e-03,  8.74327689e-04,  4.25801168e-04, -1.69457281e-03,\n",
       "        1.62404406e-03,  2.56898295e-03, -3.24658272e-03,  1.73079730e-03,\n",
       "       -4.63545156e-03,  1.05840961e-03, -2.49927001e-03,  3.74314391e-03,\n",
       "       -4.03986505e-03, -3.13854264e-03,  2.11284385e-03, -3.85049708e-03,\n",
       "       -7.07719026e-04, -1.57870380e-03,  4.61250715e-03, -2.36517062e-03,\n",
       "        7.21559501e-03,  3.30330302e-03, -1.12509517e-03, -2.73685872e-04,\n",
       "        4.68598322e-03,  2.77988117e-04, -2.08945728e-03,  4.13842705e-03,\n",
       "        1.23932820e-04, -8.08974751e-04,  7.13315152e-03,  6.71910309e-03,\n",
       "       -6.69629125e-04,  5.92768212e-03, -3.85635324e-03, -5.76570272e-04,\n",
       "        2.29345413e-03,  1.51404151e-03,  2.29713684e-03,  1.72772936e-04,\n",
       "        1.95687330e-03,  5.01440109e-04, -7.70681261e-03,  3.90699073e-03,\n",
       "       -3.33437018e-03,  4.97434765e-03,  1.91641946e-03,  6.48351109e-05,\n",
       "        6.68519982e-04,  2.66229352e-03, -2.94558816e-03, -5.51314920e-03,\n",
       "       -1.00600061e-03, -2.15627946e-03, -4.22828330e-03,  6.16501809e-03,\n",
       "        5.58496170e-03,  6.34145742e-04,  2.79227709e-03, -1.33085728e-03,\n",
       "        4.09607509e-03, -3.47843195e-03, -9.71131161e-04, -8.83617763e-03,\n",
       "       -3.06667916e-03,  2.74913799e-03,  8.65552310e-03, -7.32383981e-03,\n",
       "       -3.70217768e-03, -1.51744273e-03, -3.38210767e-03,  5.94733479e-03,\n",
       "        3.74934718e-03,  2.33352046e-04,  5.00755671e-03,  2.82440923e-03,\n",
       "        3.74163850e-03,  3.58563004e-03, -3.27516818e-03,  4.99010827e-03,\n",
       "        1.15271869e-03,  1.00154047e-03, -2.45696712e-03, -2.29261215e-03,\n",
       "       -1.18966597e-03,  9.52615547e-03,  6.19728704e-03, -9.78901510e-04,\n",
       "        2.44715098e-03, -6.26059659e-03, -6.42795873e-03,  1.97439774e-03,\n",
       "        1.97242881e-03,  3.29362754e-03, -2.52103823e-03,  3.29824843e-03,\n",
       "        2.77461027e-03,  4.40552680e-03, -2.94909366e-03, -3.86621268e-03,\n",
       "        4.87882187e-04, -6.04063786e-03,  2.01400055e-03,  1.26026232e-04,\n",
       "       -3.94535404e-03, -5.06081288e-03,  4.87352148e-04, -3.10013238e-03,\n",
       "       -2.21226110e-03, -5.90989417e-04,  2.49808631e-03,  1.08049616e-03,\n",
       "       -4.29873701e-03, -6.22362208e-03, -2.28703151e-03,  4.65456934e-03])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "norm(vectorize(\"how much wood would a wood chuck chuck, if a wood chuck could chuck wood?\"))\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an auto-generated field name and context from the form where it appeared, this function attempts to normalize the field name. Here's what's going on:\n",
    "1. It will `reCase` the variable text\n",
    "2. Then it will run the output through `regex_norm_field`\n",
    "3. If it doesn't find anything, it will use the ML model `clf_field_names`\n",
    "4. If the prediction isn't very confident, it will run it through `reformat_field`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_name(jur,group,n,per,last_field,this_field):\n",
    "\n",
    "    # Add hard coded conversions maybe by calling a function\n",
    "    # if returns 0 then fail over to ML or otherway around poor prob -> check hard-coded\n",
    "\n",
    "    if this_field not in included_fields:\n",
    "        this_field = reCase(this_field)\n",
    "\n",
    "        out_put = regex_norm_field(this_field)\n",
    "        conf = 1.0\n",
    "\n",
    "        if out_put==this_field:\n",
    "            params = []\n",
    "            for item in jurisdictions:\n",
    "                if jur== item:\n",
    "                    params.append(1)\n",
    "                else:\n",
    "                    params.append(0)\n",
    "            for item in groups:\n",
    "                if group== item:\n",
    "                    params.append(1)\n",
    "                else:\n",
    "                    params.append(0)\n",
    "            params.append(n)\n",
    "            params.append(per)\n",
    "            for vec in norm(vectorize(this_field)):\n",
    "                params.append(vec)\n",
    "\n",
    "            for item in included_fields:\n",
    "                if last_field==item:\n",
    "                    params.append(1)\n",
    "                else:\n",
    "                    params.append(0)\n",
    "\n",
    "            pred = clf_field_names.predict([params])\n",
    "            prob = clf_field_names.predict_proba([params])\n",
    "\n",
    "            conf = prob[0].tolist()[prob[0].tolist().index(max(prob[0].tolist()))]\n",
    "            out_put = pred[0]\n",
    "\n",
    "    else:\n",
    "        out_put = this_field\n",
    "        conf = 1\n",
    "\n",
    "    if out_put in included_fields:\n",
    "        if conf >= 0:\n",
    "            return \"*\"+out_put,conf # this * is a hack to show when something is in the list of known fields later. I need to fix this\n",
    "        else:\n",
    "            return reformat_field(this_field),conf\n",
    "    else:\n",
    "        return reformat_field(this_field),conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('name_thing', 0.52)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "normalize_name(\"UT\",None,2,0.3,\"null\",\"Name thing\")\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a list of AL variables and spits out suggested groupings. Here's what's going on:\n",
    "\n",
    "1. It reads in a list of fields (e.g., `[\"user_name\",\"user_address\"]`)\n",
    "2. Splits each field into words (e.g., turning `user_name` into `user name`)\n",
    "3. It then turns these ngrams/\"sentences\" into vectors using word2vec. \n",
    "4. For the collection of fields, it finds clusters of these \"sentences\" within the semantic space defined by word2vec. Currently it uses Affinity Propagation. See https://machinelearningmastery.com/clustering-algorithms-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_screens(fields=[],damping=0.7):\n",
    "    # Takes in a list (fields) and returns a suggested screen grouping\n",
    "    # Set damping to value >= 0.5 or < 1 to tune how related screens should be\n",
    "\n",
    "    vec_mat = np.zeros([len(fields),300])\n",
    "    for i in range(len(fields)):\n",
    "        vec_mat[i] = [nlp(reCase(fields[i])).vector][0]\n",
    "\n",
    "    # create model\n",
    "    model = AffinityPropagation(damping=damping)\n",
    "    #model = AffinityPropagation(damping=damping,random_state=4) consider using this to get consitent results. note will have to requier newer version\n",
    "    # fit the model\n",
    "    model.fit(vec_mat)\n",
    "    # assign a cluster to each example\n",
    "    yhat = model.predict(vec_mat)\n",
    "    # retrieve unique clusters\n",
    "    clusters = unique(yhat)\n",
    "\n",
    "    screens = {}\n",
    "    #sim = np.zeros([5,300])\n",
    "    i=0\n",
    "    for cluster in clusters:\n",
    "        this_screen = where(yhat == cluster)[0]\n",
    "        vars = []\n",
    "        j=0\n",
    "        for screen in this_screen:\n",
    "            #sim[screen]=vec_mat[screen] # use this spot to add up vectors for compare to list\n",
    "            vars.append(fields[screen])\n",
    "            j+=1\n",
    "        screens[\"screen_%s\"%i]=vars\n",
    "        i+=1\n",
    "\n",
    "    return screens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'screen_0': ['users1_name',\n",
       "  'users1_birthdate',\n",
       "  'users1_address_line_one',\n",
       "  'users1_address_line_two',\n",
       "  'users1_address_city',\n",
       "  'users1_address_state',\n",
       "  'users1_address_zip',\n",
       "  'users1_phone_number',\n",
       "  'users1_email',\n",
       "  'users1_signature'],\n",
       " 'screen_1': ['plantiffs1_name',\n",
       "  'defendants1_name',\n",
       "  'petitioners1_name',\n",
       "  'respondents1_name'],\n",
       " 'screen_2': ['docket_number'],\n",
       " 'screen_3': ['trial_court_county'],\n",
       " 'screen_4': ['signature_date']}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "fields= [\n",
    "        \"users1_name\",\n",
    "        \"users1_birthdate\",\n",
    "        \"users1_address_line_one\",\n",
    "        \"users1_address_line_two\",\n",
    "        \"users1_address_city\",\n",
    "        \"users1_address_state\",\n",
    "        \"users1_address_zip\",\n",
    "        \"users1_phone_number\",\n",
    "        \"users1_email\",\n",
    "        \"plantiffs1_name\",\n",
    "        \"defendants1_name\",\n",
    "        \"petitioners1_name\",\n",
    "        \"respondents1_name\",\n",
    "        \"docket_number\",\n",
    "        \"trial_court_county\",\n",
    "        \"users1_signature\",\n",
    "        \"signature_date\"\n",
    "        ]\n",
    "\n",
    "cluster_screens(fields,damping=0.7)\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000000000002, 1.0000000000000002, 1.0000000000000002, 1.0000000000000002, 1.0000000000000002]\n",
      "[0.8038686975124008, 0.8038686975124008, 0.8038686975124008, 0.8038686975124008, 0.8038686975124008]\n",
      "[0.8481956135581707, 0.8481956135581707, 0.8481956135581707, 0.8481956135581707, 0.8481956135581707]\n",
      "[0.826921329803093, 0.826921329803093, 0.826921329803093, 0.826921329803093, 0.826921329803093]\n",
      "[0.8197875020998185, 0.8197875020998185, 0.8197875020998185, 0.8197875020998185, 0.8197875020998185]\n",
      "[0.8059375150874605, 0.8059375150874605, 0.8059375150874605, 0.8059375150874605, 0.8059375150874605]\n",
      "[0.7847333680991196, 0.7847333680991196, 0.7847333680991196, 0.7847333680991196, 0.7847333680991196]\n",
      "[0.8077588614146448, 0.8077588614146448, 0.8077588614146448, 0.8077588614146448, 0.8077588614146448]\n",
      "[0.8619738791744108, 0.8619738791744108, 0.8619738791744108, 0.8619738791744108, 0.8619738791744108]\n",
      "[0.5654755902680005, 0.5654755902680005, 0.5654755902680005, 0.5654755902680005, 0.5654755902680005]\n",
      "[0.7270830527576246, 0.7270830527576246, 0.7270830527576246, 0.7270830527576246, 0.7270830527576246]\n",
      "[0.7066811786666043, 0.7066811786666043, 0.7066811786666043, 0.7066811786666043, 0.7066811786666043]\n",
      "[0.8033780104957245, 0.8033780104957245, 0.8033780104957245, 0.8033780104957245, 0.8033780104957245]\n",
      "[0.3710364828431793, 0.3710364828431793, 0.3710364828431793, 0.3710364828431793, 0.3710364828431793]\n",
      "[0.2775048357597198, 0.2775048357597198, 0.2775048357597198, 0.2775048357597198, 0.2775048357597198]\n",
      "[0.848285400400378, 0.848285400400378, 0.848285400400378, 0.848285400400378, 0.848285400400378]\n",
      "[0.4748926350344034, 0.4748926350344034, 0.4748926350344034, 0.4748926350344034, 0.4748926350344034]\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "vec_mat = np.zeros([len(fields),300])\n",
    "for i in range(len(fields)):\n",
    "    vec_mat[i] = [nlp(reCase(fields[i])).vector][0]\n",
    "\n",
    "parts = np.zeros([5,300])\n",
    "\n",
    "for row in vec_mat:\n",
    "    sim = []\n",
    "    for part in parts:\n",
    "        sim.append(cosine_similarity(vec_mat[0].reshape(1, -1),row.reshape(1, -1))[0][0])\n",
    "    print(sim)   \n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the text content of a pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf (file):\n",
    "    try:\n",
    "        pdfFile = PyPDF2.PdfFileReader(open(file, \"rb\"))\n",
    "        if pdfFile.isEncrypted:\n",
    "            try:\n",
    "                pdfFile.decrypt('')\n",
    "                #print ('File Decrypted (PyPDF2)')\n",
    "            except:\n",
    "                #\n",
    "                #\n",
    "                # This didn't go so well on my Windows box so I just ran this in the pdf folder's cmd:\n",
    "                # for %f in (*.*) do copy %f temp.pdf /Y && \"C:\\Program Files (x86)\\qpdf-8.0.2\\bin\\qpdf.exe\" --password=\"\" --decrypt temp.pdf %f\n",
    "                #\n",
    "                #\n",
    "                #\n",
    "                \n",
    "                command=\"cp \"+file+\" tmp/temp.pdf; qpdf --password='' --decrypt tmp/temp.pdf \"+file\n",
    "                os.system(command)\n",
    "                #print ('File Decrypted (qpdf)')\n",
    "                #re-open the decrypted file\n",
    "                pdfFile = PyPDF2.PdfFileReader(open(file, \"rb\"))\n",
    "        text = \"\"\n",
    "        for page in pdfFile.pages:\n",
    "            text = text + \" \" + page.extractText()\n",
    "        text = reCase(text)\n",
    "        text = re.sub(\"(\\.|,|;|:|!|\\?|\\n|\\]|\\))\",\"\\\\1 \",text)\n",
    "        text = re.sub(\"(\\(|\\[)\",\" \\\\1\",text)\n",
    "        text = re.sub(\" +\",\" \",text)\n",
    "        return text\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Waiver of \\n Rights\\n \\n Approved Board of District Court Judges \\n December 17, 2010\\n \\n Revised \\n November 26\\n , 2019\\n \\n Page \\n 1\\n \\n of \\n 2\\n \\n \\n \\n \\n Name\\n \\n \\n \\n \\n Address\\n \\n \\n \\n \\n City, State, Zip\\n \\n \\n \\n \\n Phone\\n \\n \\n \\n Check your email. \\n You will receive information and \\n documents at this email address. \\n \\n \\n Email\\n \\n In the District Court of Utah\\n \\n _ __ __ __ Judicial District _ __ __ __ __ __ Count\\n y\\n \\n Court Address _ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ _\\n \\n In the Matter of the Adoption of\\n \\n _ __ __ __ __\\n _ __ __ __ __ __ __ __ _\\n \\n (\\n \\n ) \\n \\n Waiver \\n of Rights\\n \\n _ __ __ __ __ _\\n _ __ __ __ _\\n _ __\\n \\n Case Number\\n \\n _ __ __ __ __ _\\n _ __ __ __ _\\n _ __\\n \\n Jud\\n ge\\n \\n _ __ __ __ __ _\\n _ __ __ __ _\\n _ __\\n \\n Commissioner\\n \\n Do not sign this document without reading it. \\n Do not sign it unless everything \\n stated is true and correct. \\n If you have any questions, \\n talk with\\n \\n an attorney\\n . \\n \\n \\n \\n You have the right to be notified of hearings and \\n to be served with papers in this \\n matter. You have the right to intervene and oppose the adoption. \\n By signing this \\n document you are giving up \\n these\\n \\n rights\\n . \\n \\n \\n \\n If you \\n want to waive your rights\\n , complete this form, sign it, \\n and \\n return\\n \\n it \\n to the \\n Petitioner\\n . \\n \\n \\n \\n If yo\\n u \\n want to intervene and \\n oppose the adoption, \\n file a motion to intervene \\n with \\n this\\n \\n court\\n \\n within 30 days after the \\n Notice of Petition to Adopt\\n \\n was served on you. \\n \\n 1\\n . \\n \\n I make this statement free from \\n duress\\n . \\n \\n Waiver of \\n Rights\\n \\n Approved Board of District Court Judges \\n December 17, 2010\\n \\n Revised \\n November 26\\n , 2019\\n \\n Page \\n 2\\n \\n of \\n 2\\n \\n \\n 2\\n . \\n \\n I am the \\n adoptee\\n \\n \\n [ ] \\n Guardian\\n \\n without the right\\n \\n to consent to the adoption\\n \\n [ ] \\n Custodian\\n \\n [ ] \\n S\\n p\\n ouse\\n \\n 3\\n . \\n \\n I understand that\\n : \\n \\n \\n \\n I have the right to be notified of hearings and to be served with papers in this \\n matter. \\n \\n \\n \\n I have the right to intervene and oppose the adoption. \\n \\n \\n \\n By signing this document \\n I am\\n \\n givin\\n g up \\n these\\n \\n rights\\n . \\n \\n 4\\n . \\n \\n Understanding all of this, \\n I \\n voluntarily \\n waive my right to \\n be notified of hearings \\n and served with papers in this matter\\n , and\\n \\n I voluntarily waive my right to \\n intervene in this matter. \\n \\n Do not sign this document without reading it. \\n Do n\\n ot sign it unless everything \\n stated is true and correct. \\n If you have any questions, \\n talk with\\n \\n an attorney\\n . \\n \\n \\n \\n I declare under \\n criminal \\n penalty \\n under the law of Utah\\n \\n that everything stated \\n in this document is true\\n . \\n \\n Signed at _ __ __ __ __ __ __ __ __ __ __ _\\n _ __ __ __ __ __ __ _ (city, and state or country) . \\n \\n \\n Sign\\n atu\\n \\n \\n \\n Date\\n \\n Printed Name'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "read_pdf(\"Waiver_Rights.pdf\")\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in a pdf, pull out basic stats, attempt to normalize its form fields, and re-write the file with the new fields (if `rewrite=1`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_form(fileloc,title=None,jur=None,cat=None,normalize=1,use_spot=0,rewrite=0):\n",
    "    f = PyPDF2.PdfFileReader(fileloc)\n",
    "\n",
    "    if f.isEncrypted:\n",
    "        pdf = pikepdf.open(fileloc, allow_overwriting_input=True)\n",
    "        pdf.save(fileloc)\n",
    "        f = PyPDF2.PdfFileReader(fileloc)\n",
    "        \n",
    "    npages = f.getNumPages()\n",
    "  \n",
    "    # When reading some pdfs, this can hang due to their crazy field structure\n",
    "    try:\n",
    "        with time_limit(15):\n",
    "            ff = f.getFields()\n",
    "    except TimeoutException as e:\n",
    "        print(\"Timed out!\")\n",
    "        ff = None   \n",
    "    \n",
    "    if ff:\n",
    "        fields = list(ff.keys())\n",
    "    else:\n",
    "        fields = []\n",
    "    f_per_page = len(fields)/npages\n",
    "    text = read_pdf(fileloc)\n",
    "    \n",
    "    if title is None:\n",
    "        title = reCase(re.search(\"(.*)\\n\",text).group(1).strip())\n",
    "\n",
    "    try:\n",
    "        #readbility = int(Readability(text).flesch_kincaid().grade_level)\n",
    "        text = re.sub(\"_\",\" \",text)\n",
    "        text = re.sub(\"\\n\",\". \",text)\n",
    "        text = re.sub(\" +\",\" \",text)\n",
    "        if text!= \"\":\n",
    "            consensus = textstat.text_standard(text)\n",
    "            readbility = eval(re.sub(\"^(\\d+)[^0-9]+(\\d+)\\w*.*\",\"(\\\\1+\\\\2)/2\",consensus))\n",
    "        else:\n",
    "            readbility = None\n",
    "    except:\n",
    "        readbility = None\n",
    "\n",
    "    if use_spot==1:\n",
    "        nmsi = spot(title + \". \" +text)      \n",
    "    else:\n",
    "        nmsi = []\n",
    "        \n",
    "    if normalize==1:\n",
    "        i = 0 \n",
    "        length = len(fields)\n",
    "        last = \"null\"\n",
    "        new_fields = []\n",
    "        new_fields_conf = []\n",
    "        for field in fields:\n",
    "            #print(jur,cat,i,i/length,last,field)\n",
    "            this_field,this_conf = normalize_name(jur,cat,i,i/length,last,field)\n",
    "            new_fields.append(this_field)\n",
    "            new_fields_conf.append(this_conf)\n",
    "            last = field\n",
    "        \n",
    "        new_fields = [v + \"__\" + str(new_fields[:i].count(v) + 1) if new_fields.count(v) > 1 else v for i, v in enumerate(new_fields)]\n",
    "    else:\n",
    "        new_fields = fields\n",
    "        new_fields_conf = []\n",
    "    \n",
    "    stats = {\n",
    "            \"title\":title,\n",
    "            \"category\":cat,\n",
    "            \"pages\":npages,\n",
    "            \"reading grade level\": readbility,\n",
    "            \"list\":nmsi,\n",
    "            \"avg fields per page\": f_per_page,\n",
    "            \"fields\":new_fields,\n",
    "            \"fields_conf\":new_fields_conf,\n",
    "            \"fields_old\":fields,\n",
    "            \"text\":text\n",
    "            }    \n",
    "    \n",
    "    if rewrite==1:\n",
    "        try:\n",
    "            if 1==1:\n",
    "                my_pdf = pikepdf.Pdf.open(fileloc, allow_overwriting_input=True)\n",
    "                fields_too = my_pdf.Root.AcroForm.Fields #[0][\"/Kids\"][0][\"/Kids\"][0][\"/Kids\"][0][\"/Kids\"]\n",
    "                #print(repr(fields_too))\n",
    "                \n",
    "                k =0\n",
    "                for field in new_fields:\n",
    "                    #print(k,field)\n",
    "                    fields_too[k].T = re.sub(\"^\\*\",\"\",field)\n",
    "                    k+=1\n",
    "\n",
    "                #f2.T = 'new_hospital_name'\n",
    "                #filename = re.search(\"\\/(\\w*\\.pdf)$\",fileloc).groups()[0]\n",
    "                #my_pdf.save('/%s'%(filename))\n",
    "                my_pdf.save(fileloc)\n",
    "            else:\n",
    "                file = PdfFileWriter()\n",
    "\n",
    "                first_page = f.getPage(0)\n",
    "\n",
    "                file.cloneDocumentFromReader(f)\n",
    "                #file.appendPagesFromReader(f)\n",
    "\n",
    "                x ={}\n",
    "                for y in ff:\n",
    "                    x[y]=\"\"\n",
    "\n",
    "                #print(x)\n",
    "\n",
    "                file.updatePageFormFieldValues(first_page,x)\n",
    "\n",
    "                output = open('blankPdf.pdf', 'wb')\n",
    "                file.write(output)  \n",
    "        except:\n",
    "            error = \"could not change form fields\"\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiver. of. . . Rights. . . . Approved. Board. of. District. Court. Judges. . . December. 17,. 2010. . . . Revised. . . November. 26. . ,. 2019. . . . Page. . . 1. . . . of. . . 2. . . . . . . . . . Name. . . . . . . . . . Address. . . . . . . . . . City,. State,. Zip. . . . . . . . . . Phone. . . . . . . . Check. your. email.. . . You. will. receive. information. and. . . documents. at. this. email. address.. . . . . . . Email. . . . In. the. District. Court. of. Utah. . . . . . . . . . . . . . . Judicial. District. . . . . . . . . . . . . . . . . . Count. . y. . . . Court. Address. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . In. the. Matter. of. the. Adoption. of. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . (. . . . ). . . . . Waiver. . . of. Rights. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Case. Number. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Jud. . ge. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Commissioner. . . . Do. not. sign. this. document. without. reading. it.. . . Do. not. sign. it. unless. everything. . . stated. is. true. and. correct.. . . If. you. have. any. questions,. . . talk. with. . . . an. attorney. . .. . . . . . . . . You. have. the. right. to. be. notified. of. hearings. and. . . to. be. served. with. papers. in. this. . . matter.. You. have. the. right. to. intervene. and. oppose. the. adoption.. . . By. signing. this. . . document. you. are. giving. up. . . these. . . . rights. . .. . . . . . . . . If. you. . . want. to. waive. your. rights. . ,. complete. this. form,. sign. it,. . . and. . . return. . . . it. . . to. the. . . Petitioner. . .. . . . . . . . . If. yo. . u. . . want. to. intervene. and. . . oppose. the. adoption,. . . file. a. motion. to. intervene. . . with. . . this. . . . court. . . . within. 30. days. after. the. . . Notice. of. Petition. to. Adopt. . . . was. served. on. you.. . . . . 1. . .. . . . . I. make. this. statement. free. from. . . duress. . .. . . . . Waiver. of. . . Rights. . . . Approved. Board. of. District. Court. Judges. . . December. 17,. 2010. . . . Revised. . . November. 26. . ,. 2019. . . . Page. . . 2. . . . of. . . 2. . . . . . 2. . .. . . . . I. am. the. . . adoptee. . . . . . [. ]. . . Guardian. . . . without. the. right. . . . to. consent. to. the. adoption. . . . [. ]. . . Custodian. . . . [. ]. . . S. . p. . ouse. . . . 3. . .. . . . . I. understand. that. . :. . . . . . . . . I. have. the. right. to. be. notified. of. hearings. and. to. be. served. with. papers. in. this. . . matter.. . . . . . . . . I. have. the. right. to. intervene. and. oppose. the. adoption.. . . . . . . . . By. signing. this. document. . . I. am. . . . givin. . g. up. . . these. . . . rights. . .. . . . . 4. . .. . . . . Understanding. all. of. this,. . . I. . . voluntarily. . . waive. my. right. to. . . be. notified. of. hearings. . . and. served. with. papers. in. this. matter. . ,. and. . . . I. voluntarily. waive. my. right. to. . . intervene. in. this. matter.. . . . . Do. not. sign. this. document. without. reading. it.. . . Do. n. . ot. sign. it. unless. everything. . . stated. is. true. and. correct.. . . If. you. have. any. questions,. . . talk. with. . . . an. attorney. . .. . . . . . . . . I. declare. under. . . criminal. . . penalty. . . under. the. law. of. Utah. . . . that. everything. stated. . . in. this. document. is. true. . .. . . . . Signed. at. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . (city,. and. state. or. country). .. . . . . . . Sign. . atu. . . . . . . . Date. . . . Printed. Name\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'12th and 13th grade'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "text = read_pdf(\"Waiver_Rights.pdf\")\n",
    "text = re.sub(\"_\",\" \",text)\n",
    "text = re.sub(\"\\s\",\". \",text)\n",
    "text = re.sub(\" +\",\" \",text)\n",
    "print(text)\n",
    "print(text!=\"\")\n",
    "textstat.text_standard(text)\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Waiver of',\n",
       " 'category': None,\n",
       " 'pages': 2,\n",
       " 'reading grade level': 7.5,\n",
       " 'list': [],\n",
       " 'avg fields per page': 0.0,\n",
       " 'fields': [],\n",
       " 'fields_conf': [],\n",
       " 'fields_old': [],\n",
       " 'text': 'Waiver of . Rights. . Approved Board of District Court Judges . December 17, 2010. . Revised . November 26. , 2019. . Page . 1. . of . 2. . . . . Name. . . . . Address. . . . . City, State, Zip. . . . . Phone. . . . Check your email. . You will receive information and . documents at this email address. . . . Email. . In the District Court of Utah. . Judicial District Count. y. . Court Address . . In the Matter of the Adoption of. . . . . (. . ) . . Waiver . of Rights. . . . . . Case Number. . . . . . Jud. ge. . . . . . Commissioner. . Do not sign this document without reading it. . Do not sign it unless everything . stated is true and correct. . If you have any questions, . talk with. . an attorney. . . . . . You have the right to be notified of hearings and . to be served with papers in this . matter. You have the right to intervene and oppose the adoption. . By signing this . document you are giving up . these. . rights. . . . . . If you . want to waive your rights. , complete this form, sign it, . and . return. . it . to the . Petitioner. . . . . . If yo. u . want to intervene and . oppose the adoption, . file a motion to intervene . with . this. . court. . within 30 days after the . Notice of Petition to Adopt. . was served on you. . . 1. . . . I make this statement free from . duress. . . . Waiver of . Rights. . Approved Board of District Court Judges . December 17, 2010. . Revised . November 26. , 2019. . Page . 2. . of . 2. . . 2. . . . I am the . adoptee. . . [ ] . Guardian. . without the right. . to consent to the adoption. . [ ] . Custodian. . [ ] . S. p. ouse. . 3. . . . I understand that. : . . . . I have the right to be notified of hearings and to be served with papers in this . matter. . . . . I have the right to intervene and oppose the adoption. . . . . By signing this document . I am. . givin. g up . these. . rights. . . . 4. . . . Understanding all of this, . I . voluntarily . waive my right to . be notified of hearings . and served with papers in this matter. , and. . I voluntarily waive my right to . intervene in this matter. . . Do not sign this document without reading it. . Do n. ot sign it unless everything . stated is true and correct. . If you have any questions, . talk with. . an attorney. . . . . . I declare under . criminal . penalty . under the law of Utah. . that everything stated . in this document is true. . . . Signed at . (city, and state or country) . . . . Sign. atu. . . . Date. . Printed Name'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "#parse_form(\"../data/processed/www.utcourts.gov/forms/898269a99ff1c65be10b1ae35bb34ba469fc14b7301b7ed7b126d195.pdf\",title=None,jur=\"UT\",cat=None,normalize=1)\n",
    "#parse_form(\"../data/processed/www.utcourts.gov/forms/2532cd2b6d3aaff8c47726a0abd168fb4e5cdb4977c065cd27bde8c7.pdf\",title=None,jur=\"UT\",cat=None,normalize=1)\n",
    "#parse_form(\"../data/processed/www.utcourts.gov/forms/6ec7576210513907e699b5adf3397639507c688801a60bc34c201984.pdf\",title=None,jur=\"UT\",cat=None,normalize=1)\n",
    "#parse_form(\"../data/processed/mjbportal.courts.maine.gov/forms/1519fe450d870a36a428a0b006c0665a.pdf\",title=None,jur=\"UT\",cat=None,normalize=1)\n",
    "#parse_form(\"../data/processed/www.courts.ca.gov/forms/3979f1c1c9f165ccac026b26cf20252c.pdf\",title=None,jur=\"UT\",cat=None,normalize=1)\n",
    "#parse_form(\"../data/processed/www.courts.michigan.gov/forms/52b2bf502a4bd8bc3a39a494a0ea5b0f491552e4d2da2ebe82beba3d.pdf\",title=None,jur=\"UT\",cat=None,normalize=1)\n",
    "\n",
    "#parse_form(\"../data/processed/www.utcourts.gov/forms/d94720b568d800e2510fbc04955687282a7e7419b78565d3e52c461c.pdf\",title=None,jur=\"MI\",cat=None,normalize=1,use_spot=1,rewrite=0)\n",
    "#parse_form(\"../data/processed/www.courts.michigan.gov/forms/147d1063a642a9f94693331190cc14599152610dc5cd489b5d17e46d.pdf\",title=None,jur=\"MI\",cat=None,normalize=1,use_spot=1,rewrite=0)\n",
    "#parse_form(\"../data/processed/www.courts.ca.gov/forms/e2c17a8503879d28d12932434d7c755b.pdf\",title=None,jur=\"CA\",cat=None,normalize=1,use_spot=1,rewrite=0)\n",
    "\n",
    "#parse_form(\"../data/processed/www.courts.ca.gov/forms/0d795fb4c4e35655370b5a6defa6b5cb.pdf\",title=None,jur=\"CA\",cat=None,normalize=1,use_spot=1,rewrite=0)\n",
    "\n",
    "parse_form(\"Waiver_Rights.pdf\",title=None,jur=\"UT\",cat=None,normalize=1,use_spot=1,rewrite=0)\n",
    "\n",
    "#my_pdf = pikepdf.Pdf.open(\"../data/processed/www.courts.ca.gov/forms/0d795fb4c4e35655370b5a6defa6b5cb.pdf\", allow_overwriting_input=True)\n",
    "#fields_too = my_pdf.Root.AcroForm.Fields #[0][\"/Kids\"][0][\"/Kids\"][0][\"/Kids\"][0][\"/Kids\"]\n",
    "#print(repr(fields_too))\n",
    "\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_complexity(text,fields,reading_lv):\n",
    "    \n",
    "    # check for fields that requier user to look up info, when found add to complexity\n",
    "    # maybe score these by minutes to recall/fill out\n",
    "    # so, figure out words per minute, mix in with readability and page number and field numbers\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "#      Start Test\n",
    "#########################\n",
    "\n",
    "# Save this notebook, then run this cell.\n",
    "\n",
    "import nbformat\n",
    "from nbconvert import PythonExporter\n",
    "from datetime import date\n",
    "today = date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "with open('001 Package Code.ipynb') as fh:\n",
    "    nb = nbformat.reads(fh.read(), nbformat.NO_CONVERT)\n",
    "\n",
    "exporter = PythonExporter()\n",
    "source, meta = exporter.from_notebook_node(nb)\n",
    "\n",
    "with open('lib/lit_explorer.py', 'w+') as fh:\n",
    "    fh.writelines(source)\n",
    "\n",
    "local_load =\"\"\"\n",
    "included_fields = load(os.path.join(os.path.dirname(__file__), 'data', 'included_fields.joblib'))\n",
    "jurisdictions = load(os.path.join(os.path.dirname(__file__), 'data', 'jurisdictions.joblib'))\n",
    "groups = load(os.path.join(os.path.dirname(__file__), 'data', 'groups.joblib'))\n",
    "clf_field_names = load(os.path.join(os.path.dirname(__file__), 'data', 'clf_field_names.joblib'))\n",
    "with open(os.path.join(os.path.dirname(__file__), '../../data/keys', 'spot_token.txt'), 'r') as file:\n",
    "    spot_token = file.read().rstrip()\n",
    "\"\"\"\n",
    "\n",
    "with open(\"lib/lit_explorer.py\", \"r\") as file:\n",
    "    content = file.read() # read everything in the file\n",
    "    content = re.sub(\"#!/usr/bin/env python\\n\",\"\",content,flags=re.M)\n",
    "    content = re.sub(\"# coding: utf-8\\n\",\"\",content,flags=re.M)\n",
    "    content = re.sub(\"# load local stuff\\n\",local_load,content,flags=re.M)\n",
    "    content = re.sub(\"(?<=#{25}\\n#\\s{6}Start Test\\n#{25}\\n)(^(?!.*#{25}).*$\\n)*(?=#{25}\\n#\\s{7}End Test\\n#{25}\\n)\",\"\",content,flags=re.M)\n",
    "    content = re.sub(\"#{25}\\n#\\s{6}Start Test\\n#{25}\\n|#{25}\\n#\\s{7}End Test\\n#{25}\\n|#\\sIn\\[(\\d*|\\s*)\\]:\\n\",\"\",content,flags=re.M)\n",
    "    content = re.sub(\"\\n\\n\\n\\n+\",\"\\n\\n\",content,flags=re.M)\n",
    "    content = re.sub(\"^\\n+\",\"\",content)\n",
    "    \n",
    "with open(\"lib/lit_explorer.py\", \"w\") as file:\n",
    "    file.write(\"# Updated on \"+today+\"\\n\\n\"+content)\n",
    "\n",
    "#########################\n",
    "#       End Test\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
